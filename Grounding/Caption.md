# Image/Video Caption

## Good Tutorials
- https://www.leiphone.com/news/201805/aQXoPMX51DD1C7VC.html

## Benchmark
- MSCOCO
- http://www.sohu.com/a/313942390_651893?sec=wd

## Unclassified
- Partially-Supervised Image Captioning. NIPS'18
- Dahua Lin. A Neural Compositional Paradigm for Image Captioning. NIPS'18
- Weakly Supervised Dense Event Captioning in Videos. NIPS'18
- Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog. NIPS'18

## Classical
- Stanford
	- **NeuralTalk**: A. Karpathy. https://github.com/karpathy/neuraltalk
	- A. Karpathy and L. Fei-Fei. Deep visual-semantic alignments for generating image descriptions. CVPR 2015
	- R. Krishna, K. Hata, F. Ren, L. Fei-Fei, and J. C. Niebles. Dense-Captioning events in videos. ICCV 2017
- Alex/Tamara Berg:
	- G. Kulkarni, V. Premraj, S. Dhar, S. Li, Y. Choi, A. C. Berg, and T. L. Berg. Baby talk: Understanding and generating image descriptions. CVPR 2011
- Dhruv/Devi/FAIR:
	- J. Lu, J. Yang, D. Batra, and D. Parikh. Neural baby talk. CVPR 2018
- Google:
	- O Vinyals, A Toshev, S Bengio, D Erhan. **Show and Tell**: Lessons learned from the 2015 MSCOCO Image Captioning Challenge. 2015
- Attention:
	- K. Xu, J. Ba, R. Kiros, K. Cho, A. C. Courville, R. Salakhutdinov, R. S. Zemel, and Y. Bengio. Show, attend and tell: Neural image caption generation with visual attention. In ICML, 2015.
- **NMN**: Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Deep compositional question answering
with neural module networks. CVPR'16.

## Reasoning
- **VCR**: Visual Commonsense Reasoning. CVPR'19

## Novel Object
- Novel Visual Concept
	- Junhua: 
		- Novel Visual Concept (NVC) dataset https://github.com/mjhucla/NVC-Dataset
		- TF-mRNN: https://github.com/mjhucla/TF-mRNN
		- mRNN-CR: https://github.com/mjhucla/mRNN-CR