# Benchmarks

## GLUE
- **GLUE**: A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. 2018

## Natural Language Inference
- entailment, contradiction or neutral.

## Language Modeling
- **text8**: Mahoney, M. 2009. Large text compression benchmark. http://www.mattmahoney.net/text/text.html.
- **enwik8**
- **lm1b**: Chelba, C.; Mikolov, T.; Schuster, M.; Ge, Q.; Brants, T.; Koehn, P.; and Robinson, T. 2013. One billion word benchmark for measuring progress in statistical language modeling. 2013
- **Newsroom**: Max Grusky, Mor Naaman, and Yoav Artzi. Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies. NAACL'18

## Sentiment analysis
- SST-5. Stanford Sentiment Treebank Socher. et al., 2013

## NER (Named entity extraction)
- CoNLL 2003: NER task (Sang and Meulder, 2003)

## Question Answering
- SQuAD
- Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. 2017
- Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and Kaheer Suleman. Newsqa: A machine comprehension dataset. 2016

## Misc
- Hector Levesque, Ernest Davis, and Leora Morgenstern. The winograd schema challenge. PKDD'12

## Deeper Understanding
- Rowan Zellers, Ari Holtzman, Elizabeth Clark, Lianhui Qin, Ali Farhadi, Yejin Choi. Evaluating Machines by their Real-World Language Use. 2020
	- Benchmark: Giving helpful advice;
	- http://rowanzellers.com/advice/
