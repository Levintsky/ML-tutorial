## 2D Composiontal/Template Modeling

## Progressive
- Strokes:
	- **SPRIAL**. Y. Ganin, T. Kulkarni, Igor Babuschkin, S. M. Ali Eslami, Oriol Vinyals. SPIRAL: Synthesizing Programs for Images using Reinforced Adversarial Learning. ICML'18
		- https://github.com/deepmind/spiral

## 2D PM
- Template/primitives:
	- Kevin Ellis, Armando Solar-Lezama, Joshua B. Tenenbaum. Unsupervised Learning by Program Synthesis. NIPS'15
		- https://github.com/ellisk42/sasquatch
		- Sketching
- Physics:
	- Zhijian Liu, William T. Freeman, Joshua B. Tenenbaum, and Jiajun Wu. Physical Primitive Decomposition. ECCV'18
		- http://ppd.csail.mit.edu/
- Neural-Symbolic Reasoning:
	- **NMN**: J Andreas, M Rohrbach, T Darrell, D Klein. Neural Module Networks. CVPR'16
	- **clevr-iep**: Justin Johnson, Judy Hoffman, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick, Ross Girshick. Inferring and Executing Programs for Visual Reasoning. ICCV'17
		- https://github.com/facebookresearch/clevr-iep
	- **sg2im**: Justin Johnson, Agrim Gupta, Li Fei-Fei. Image Generation from Scene Graphs. CVPR'18
		- https://github.com/google/sg2im
	- **Neural-Symbolic VQA**: Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli, Joshua B. Tenenbaum. Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding. NeurIPS 2018
		- http://nsvqa.csail.mit.edu/
		- An interpretable VQA model that disentangles language reasoning from visual understanding
		- For visual understanding, first perform objects segmentation and then learn to obtain structural scene representation (with supervision) such as color, size, shape, position.
		- For language reasoning, they learn to translate natural language question into a deterministic program such as filter_shape(scene, large) or count(scene). 
		- Finally, they execute the program on the structural scene representation to obtain the final answer
		- 99.8% on CLEVR
	- Yunchao Liu, Zheng Wu, Daniel Ritchie, William T Freeman, Joshua B Tenenbaum, and Jiajun Wu. Learning to describe scenes with programs. ICLR'19
		- Problem definition: focus on learning the high-level scene regularities described by loop structures:\
			<img src="/Generative/images/pm/learn-to-describe.png" alt="drawing" width="500"/>
		- An object parser predicts the segmentation mask and attributes for each object in the image; (Mask-RCNN, ResNet-34)
		- A group recognizer predicts the group that each object belongs to; concatenate original, mask of self, mask of objects, then ResNet + fc output two heads (same group and category?)
		- DSL; learn with seq2seq LSTM, each step output a token t and a parameter matrix P;\
			<img src="/Generative/images/pm/learn-to-describe-dsl.png" alt="drawing" width="450"/>
		- Algorithm:\
			<img src="/Generative/images/pm/learn-to-describe-alg.png" alt="drawing" width="450"/>
	- **NSCL**: Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B. Tenenbaum, Jiajun Wu. The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences from Natural Supervision. ICLR'19
		- http://nscl.csail.mit.edu/
	- **NGSI**: Sidi Lu, Jiayuan Mao, Joshua B. Tenenbaum, Jiajun Wu. Neurally-Guided Structure Inference. ICML'19
		- https://github.com/desire2020/NGSI
	- **PGIM**: Jiayuan Mao, Xiuming Zhang, Yikai Li, William T. Freeman, Joshua B. Tenenbaum, Jiajun Wu. Program-Guided Image Manipulators. ICCV'19
		- http://pgim.csail.mit.edu
	- Chi Han, Jiayuan Mao, Chuang Gan, Joshua B. Tenenbaum, Jiajun Wu. Visual Concept-Metaconcept Learning. NIPS'19
		- http://vcml.csail.mit.edu/
		- https://github.com/Glaciohound/VCML
- De-render, Inverse Graphics:
	- **Picture**: Kulkarni, T. D., Kohli, P., Tenenbaum, J. B., and Mansinghka, V. Picture: A probabilistic programming language for scene perception. CVPR'15
	- **DC-IGN**: Kulkarni, T. D., Whitney, W. F., Kohli, P., and Tenenbaum, J. Deep convolutional inverse graphics network. NIPS'15
		- Probabilistic programming:\
			<img src="/Graphics/images/dc_ign.png" alt="drawing" width="600"/>
	- **NGPM**: Daniel Ritchie, Anna Thomas, Pat Hanrahan, Noah Goodman. Neurally-Guided Procedural Models: Amortized Inference for Procedural Graphics Programs using Neural Networks. NIPS'16
		- Problem setup: for a shape, generate particles to cover;
		- Probabilistic Programming with NN;\
			<img src = '/Generative/images/pm/ngpm1.png' width = '500'>
		- Minimize KL divergence PCM and PGM;\
			<img src = '/Generative/images/pm/ngpm2.png' width = '400'>
	- **R3NN**: Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, and Pushmeet Kohli. Neuro-symbolic program synthesis. ICLR'17
	- Tony Beltramelli. Pix2code: Generating code from a graphical user interface screenshot. EICA'18
		- GUI image to markup-like code;
	- Rudy Bunel, Matthew Hausknecht, Jacob Devlin, Rishabh Singh, and Pushmeet Kohli. Leveraging grammar and reinforcement learning for neural program synthesis. ICLR'18
		- goes beyond the pure supervised learning setting and improves performance on diversity and syntax by leveraging grammar and reinforcement learning;
	- **VON**: Jun-Yan Zhu, Zhoutong Zhang, Chengkai Zhang, Jiajun Wu, Antonio Torralba, Joshua B. Tenenbaum, William T. Freeman. Visual Object Networks: Image Generation with Disentangled 3D Representation. NIPS'18
		- http://von.csail.mit.edu/
		- https://github.com/junyanz/VON
		- Problem setup: latent z to 3D-aware image;
		- Assumption: image formation = shape + viewpoint + texture;
		- Model: category specific;
		- Algorithm:\
			<img src = '/Generative/images/pm/von.png' width = '400'>
		- 1. Train z to 3D voxel with WGAN-GP;
		- 2. Input: camera parameters and 3D voxel, output 2.5D sketches [Tulsiani'17]; z-view (elevation and azimuth) sampled from training prior;
		- 3. G_texture(v-2.5D, z-texture), need to model object texture, illumitation and differentiable rendering, handled with unpaired image-to-image translation (relaxed 1-1 mapping CycleGAN);
- Progressive CNN:
	- J Wu, JB Tenenbaum, P Kohli. Neural scene de-rendering. CVPR'17
		- Problem setup: image to xml;\
			<img src = '/Generative/images/pm/derender1.png' width='350'>
		- Approach: add element one by one;\
			<img src = '/Generative/images/pm/derender2.png' width='500'>
	- **Deep-Synth**: Kai Wang, Manolis Savva, Angel X. Chang, and Daniel Ritchie. Deep Convolutional Priors for Indoor Scene Synthesis. SIGGRAPH'18
		- https://github.com/brownvc/deep-synth
		- PM: add object one by one; BEV;\
			<img src = '/Generative/images/pm/indoor-prior.png' width = '400'>
	- Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, Josh Tenenbaum. Learning to Infer Graphics Programs from Hand-Drawn Images, NIPS'18
		- Problem: Noisy input (data augmentation); output program;
		- One at a time:\
			<img src = '/Generative/images/pm/latex.png' width = '450'>
		- Combining NGPM [4] and Attend-Infer-Repeat [5]
		- Learn a loss function?
		- DSL [11]
		- Prefer shorter program (with explicit reward)
		- Sketch-tool [1] to refine program: constraint-based SAT solver to perform program search and is much slower
	- Daniel Ritchie, Kai Wang, and Yu-an Lin. Fast and Flexible Indoor Scene Synthesis via Deep Convolutional Generative Models. CVPR'19
		- Problem setup: generative model with empty canvas and object count, one at a time;\
			<img src = '/Generative/images/pm/indoor-synth1.png' width = '400'>
		- Next object category: auxiliary STOP;
		- Object location: FCN, heat map;
		- Object orientation: cVAE for multi-modality;
		- Object dimension: cVAE;
- All objects/primitives at once:
	- **3D-SDN**: Shunyu Yao, Tzu Ming Harry Hsu, Jun-Yan Zhu, Jiajun Wu, Antonio Torralba, William T. Freeman, Joshua B. Tenenbaum. 3D-Aware Scene Manipulation via Inverse Graphics. NIPS'18
		- http://3dsdn.csail.mit.edu/
		- https://github.com/ysymyth/3D-SDN
		- Algorithm:\
			<img src = '/Generative/images/pm/3d-sdn.png' width = '400'>