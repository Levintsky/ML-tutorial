# Bandit

## NIPS'19
- Soumya Basu, Rajat Sen, Sujay Sanghavi, Sanjay Shakkottai. Blocking Bandits
- Aadirupa Saha, Aditya Gopalan. Combinatorial Bandits with Relative Feedback
- David Martínez-Rubio, Varun Kanade, Patrick Rebeschini. Decentralized Cooperative Stochastic Bandits
- Gi-Soo Kim, Myunghee Cho Paik. Doubly-Robust Lasso Bandit
- Tianyuan Jin, Jieming SHI, Xiaokui Xiao, Enhong Chen. Efficient Pure Exploration in Adaptive Round Model
- Tobias Sommer Thune, Nicolò Cesa-Bianchi, Yevgeny Seldin. Nonstochastic Multiarmed Bandits with Unrestricted Delays
- Baekjin Kim, Ambuj Tewari. On the Optimality of Perturbations in Stochastic and Adversarial Multi-armed Bandit Problems
- David Simchi-Levi, Yunzong Xu. Phase Transitions and Cyclic Phenomena in Bandits with Switching Constraints
- Virag Shah, Ramesh Johari, Jose Blanchet. Semi-Parametric Dynamic Contextual Pricing
- Sayak Ray Chowdhury, Aditya Gopalan. Bayesian Optimization under Heavy-tailed Payoffs
- Julian Zimmert, Tor Lattimore. Connections Between Mirror Descent, Thompson Sampling and the Information Ratio
- Yogev Bar-On, Yishay Mansour. Individual Regret in Cooperative Nonstochastic Multi-Armed Bandits
- Mohammad Sadegh Talebi, Odalric-Ambrym Maillard. Learning Multiple Markov Chains via Adaptive Allocation
- Sanae Amani, Mahnoosh Alizadeh, Christos Thrampoulidis. Linear Stochastic Bandits Under Safety Constraints
- Nima Hamidi, Mohsen Bayati, Kapil Gupta. Personalizing Many Decisions with High-Dimensional Covariates
- Rémy Degenne, Wouter Koolen, Pierre Ménard. Non-Asymptotic Pure Exploration by Solving Games
- Ilai Bistritz, Zhengyuan Zhou, Xi Chen, Nicholas Bambos, Jose Blanchet. Online EXP3 Learning in Adversarial Bandits with Delayed Feedback
- Shinji Ito, Daisuke Hatano, Hanna Sumita, Kei Takemura, Takuro Fukunaga, Naonori Kakimura, Ken-Ichi Kawarabayashi. Oracle-Efficient Algorithms for Online Linear Optimization with Bandit Feedback
- Young Hun Jung, Ambuj Tewari. Regret Bounds for Thompson Sampling in Episodic Restless Bandit Problems
- Chao Tao, Saúl Blanco, Jian Peng, Yuan Zhou. Thresholding Bandit with Optimal Aggregate Regret
- Yoan Russac, Claire Vernade, Olivier Cappé. Weighted Linear Bandits for Non-Stationary Environments
