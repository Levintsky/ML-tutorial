# Dynamical Systems, ODE, PDE

## Basics on Dynamic System
- Books:
	- Hairer and Peters. Solving ordinary differential equations I. Springer Berlin Heidelberg, 1987.
	- D Bertsekas. Dynamic programming and optimal control, volume 1. Athena scientific Belmont, MA, 1995.
	- D Greenwood. Advanced dynamics. Cambridge University Press, 2006.
	- C Wit, B Siciliano, and G Bastin. Theory of robot control. Springer Science & Business Media, 2012.
- Background (physics):
	- Constraint:
		- Holomonic: f(rk, t) = 0;
		- Non-holomonic: g(q, dq/ddt, t) = 0;
	- Standard/Cartesian coordinate:
		- coordinate: rj = rj(q(t))
		- velocity: v, vk = drk/dt = ∑..j ∂rj/∂qi dqi/dt
	- Generalized:
		- Coordinates: q(t);
		- Velocity: dq/dt;
		- Force: Qi = ∑ Fj ∂rj/∂qi
		- Momentum: Pi = ∂T/∂qi', canonically conjugate to qi;
	- Assumption:
		- Interal force does no work on δr; ∑F δr can cancel internal;
		- ∑Fi δri = 0;
	- Optimize x=x(t) s.t. J(x(t)) = ∫a.b F(t,x,x')dx
		- δJ = ∫a.b [F(t,x+δx,x'+δx')-F(t,x,x')]dx
		- δJ = 0 ⇒ d(∂F/∂x')dt = ∂F/∂x (Euler-Lagrange eqn)
	- Lagrange Equation: d/dt[∂L/∂qi'] - ∂T/∂qi = Qi
		- Lagrange-Eqn is similar in form with EL
		- To minimize S = ∫Ldt
	- T: kinetic; V: potential; Lagrange L=T-V;
	- All force conservative: Fi = -∂V/∂ri
		- Generalized force: Qi = - ∂V/∂qi
		- ∂V/∂qi' = 0;
		- Lagrange equation becomes: d/dt[∂L/∂qi'] - ∂L/∂qi = 0;
	- Non conservative force τi: d/dt[∂L/∂qi'] - ∂L/∂qi = τi;
	- Define energy with Legendre transform:
		- H = ∑..i qi' ∂L/∂qi' - L = ∑..i Piqi' - L
		- dq/dt = ∂H/∂p, dp/dt = -∂H/∂q
- Classical ODE numerical solvers:
	- Forward Euler (simplest RK);
	- Midpoint, leapfrog;
	- Backward Euler;
	- Runge-Kutta method: classical RK4;
- Survey/Tutorial:
	- L Ruthotto and E Haber. Deep neural networks motivated by partial differential equations. 2018
	- https://www.youtube.com/watch?v=G2n2nJnh5kc&t=1391s
	- https://www.youtube.com/watch?v=1mVycBKb1TE
- Optimal Control, Diffential equation, adjoint method:
	- Pontryagin's maximum principle (Boltyanskii et al., 1960; Pontryagin, 1987)
		- dx/dt = f(x, u); x(0) = x0; u(t) control;
		- Objective: J = Ψ(x(T)) + ∫0.T L(x(t),u(t))dt
	- Define Hamilton H(x(t), u(t), λ(t), t) = λ(t)†f(x, u) + L(x, u)
	- Optimal trajectory x∗, u∗ should satisfy:
		- H(x∗(t), u∗(t), λ∗(t), t) ≤ H(x(t), u(t), λ(t), t)
		- -dλ/dt = H∗(t) = λ∗(t)†f∗(t) + L∗(t)
		- λ(T) = Ψ(x(T))
	- About adjoint method: https://blog.csdn.net/liangdaojun/article/details/100633277
	- Adjoint sensitivity analysis for differential-algebraic equations: algorithms and software. JIAM J. Sci. Comput 2003
- Fixed point:
	- https://zhuanlan.zhihu.com/p/58507915
	- http://wwwf.imperial.ac.uk/metric/metric_public/numerical_methods/iteration/fixed_point_iteration.html
- Combined with neural network:
	- ML for the dynamics (differential equation);
	- ML for the solver;

## Unclassified
- **IQC**: L Lessard, B Recht, A Packard. Analysis and Design of Optimization Algorithms via Integral Quadratic Constraints. 2015

## ODE-Inspired Design
- Insight: ResNet/PolyNet/FractalNet/RevNet, can be interpreted as different numerical discretizations of differential equations;
- Forward Euler:
	- FractalNet: G Larsson, M Maire, G Shakhnarovich. FractalNet: Ultra-Deep Neural Networks without Residuals. ICLR'17
		- Insight: Runge-Kutta;
		- An ODE view: xn+1 = k1 xn + k2(k3 xn + f1(xn)) + f2(k3 xn+f1(xn))
 	- LM-ResNet: Y Lu, A Zhong, Q Li, and B Dong. Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations. ICML'18
		- https://web.stanford.edu/~yplu/proj/lm/
		- un+1 = (1-kn)un + kn un-1 + fn(un); (2-step)
- Backward Euler:
	- PolyNet: X Zhang, Z Li, C C Loy, D Lin. PolyNet: A Pursuit of Structural Diversity in Very Deep Networks. CVPR'17
		- https://github.com/CUHK-MMLAB/polynet
		- To approximate: un+1 = (I-Δt f)^(-1) un
		- (I+F+F^2+...)x := x + F(x) + F(F(x))
- Hamilton-inspired:
	- E Haber and L Ruthotto. Stable architectures for deep neural networks. Inverse Problems 2017
		- Dynamic: dy/dt = σ(K(t)y(t)+b(t))
		- Condition of stability: real part of Jacobian's Eigenvalue <= 0; Which requires constraint. The paper proposes an intrinsically stable method;
		- Model: 1 Layer ResNet, inspired by Hamiltonian system;
			- dY/dt = σ(K(t)Z(t)+b(t))
			- dZ/dt = -σ(K(t)Y(t)+b(t))
	- B Chang, L Meng, E Haber, et al. Reversible architectures for arbitrarily deep residual neural networks. AAAI'18
		- Insigh: ODE version of RevNet, Hamilton-like to make system stable;
		- Module: 2 Layer NN;
			- dY(t)/dt = K1(t)σ(K1(t)Z(t)+b(t))
			- dZ(t)/dt = -K2(t)σ(K2(t)Z(t)+b(t))
		- Middle-point; Leapfrog Network; make use of the trick Y(j+1)-Y(j-1)/2h=F(Yj)
- Multiscale: solve resolution i, then finer;
	- Haber, E.; Ruthotto, L.; and Holtham, E. Learning across scales-multiscale methods for convolution neural networks. AAAI'17
		- Supervised learning from optimal control formulation:
			- min 1/m∑j=1..m S(g(hWy+μ), cj) + R(W, μ, s, b)
			- s.t. yk+1 = yk + δt σ(yk, θ)
	- B Chang, L Meng, E Haber, F Tung, D Begert. Multi-level residual networks from dynamical systems view. ICLR'18
		- Insight: multi-grid ODE; allow adding new layers if current time resolution not sufficient for modeling;
- Noise/stability-inspired:
	- EnResNet: B Wang, B Yuan, Z Shi, S Osher. ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and Robust Accuracies. NIPS'19
		- Insight:
			- Modify ResNets by injecting a variance specified Gaussian noise, and it results in a special type of neural stochastic ODE.
			- We average over the production of multiple jointly trained modified ResNets to get the final prediction;
		- https://github.com/BaoWangMath/EnResNet
		- Original: xl+1 = xl + F(xl)
		- Proposed: xl+1 = xl + F(xl) + σN(0,1)
- Invertible:
	- RevNet: A Gomez, M Ren, R Urtasun, and R Grosse. The reversible residual network: Backpropagation without storing activations. NIPS'17
		- https://github.com/renmengye/revnet-public
		- Insight: modularized to make computation reversible: activation saving not required for bp;
		- Forward (left) and reverse (right):
			- z1 = x + F(x2), z1 = y1;
			- y2 = x2 + G(z1), x2 = y2 - G(z1);
			- y1 = z1,         x1 = z1 - F(x2);
		- The backprop: customized, constructing the value first;
	- i-ResNet: J Behrmann, W Grathwohl, R Chen, D Duvenaud, J Jacobsen. Invertible Residual Networks. ICML'19
		- https://github.com/jhjacobsen/invertible-resnet
		- Main insight: same as RevNet and flow-based methods. but free-form;
			- Add Spectral-Norm to make g() contractive i.e., Lip(g(θ)) < 1.
			- Then backward Euler to compute x(t+1) from x(t) as fixed point:
				- Iterate n times xi+1 = y - g(xi), with x0=y;
		- Flow ln(px(x)) = ln(pz(z))+ln|det(JF(x))|, with JF as the Jacobian of F()
			- since F=I+g(), Taylor expansion: tr(ln(I+Jg(x))) = ∑k (-1)^k+1 tr(Jg)/k;
		- Three computation drawbacks: (1) evaluate tr(J); (2) power of J; (3) Taylor has infinite terms;
		- For (1), (2), the approximate trick;
		- For (3), truncated at n steps;

## Continuous Neural Net/NODE
- Problem setup: z(t) evolves through time:
	- z(T) = z(t0) + ∫t0..T f(z(τ), θ)dτ
	- Feature/loss/supervision at z(T);
- Tricks:
	- OTD: optimize-then-discretize used in MSA, NODE, FFJORD, ...
		- OTD: α0 = α1(I+∂f(z1,θ)/∂z1); α(t) adjoint
	- DTO: need to backprop inside the solver, expensive;
		- DTO: ∂L/∂z0 = ∂L/∂z1(I+∂f(z0,θ)/∂z0)
	- Both OTD and DTO error scales at O(dt)
	- Trace estimation trick: Skilling-Hutchinson estimator
- MSA: Q Li, L Chen, C Tai, W E. Maximum Principle Based Algorithms for Deep Learning. JMLR'18
	- Insight: also leverage co-state (adjoint) + backward ODE;
	- Problem setup:
		- Each data init: K data point, (x1,...,xK) starting at t=0;
		- dX/dt=f(t,X,θ) parametrized by a NN;
		- Supervision: fitting at terminal t=T + regularization ∫L;
			- minθ ∑i=1..K Φi(XiT) + ∫0..T L(θt)dt
		- dXi/dt = f(t,Xit, θt), Xi0=xi
	- OTD (optimize then discretize)
	- Optimal Control Theory (Pontryagin's Maximum Principle) let Hamilton H as:
		- H(t,x,p,θ) = p f(t,x,θ) - L(θ)
		- Then, exist optimal θ and co-state P s.t.
		- dXt/dt = ∇p H; X0 = x;
		- dP/dt = -∇x H; P = -∇Φ(xT)
	- Algorithms:
		- Basic-MSA:
			- Solve dX(θk,t)/dt = f, X(θk, 0)=x; (forward ODE)
			- Solve dp(θk,t)/dt = -∇x H;, P(T) = -∇Φ(xT); (backward ODE)
			- Optimize θ to maximize H(.)
- NODE: R Chen, et. al. NeurIPS'18
	- Insight: bp by adjoint rather than keeping forward graph;
		- BP requires saving ∂f/∂z and ∂f/∂θ + backward ODE solver;
	- https://github.com/rtqichen/torchdiffeq
	- Let: at=∂L/∂zt
	- Residual Net:
		- Forward: z(t+h) = zt+hf(zt)
		- Backward: at = a(t+h) + ha(t+h)∂f(zt)/∂zt
		- Params: ∂L/∂θ = h a(t+h) ∂f(zt,θ)/∂θ
	- NODE:
		- Forward: z(t+1) = zt+∫t..t+1 f(zτ)dτ
		- Backward: at = a(t+1) + ∫t..t+1 a(τ)∂f(zτ)/∂zτ dτ
		- Params: ∂L/∂θ = ∫t..t+1 a(τ) ∂f(zτ,θ)/∂θ dτ
	- Implementation details:
		- Forward: at each time t, numerical integral to get f(z, θ) and save extra info -a(t)∂f/∂z, -a(t)∂f/∂θ;
		- Backward: ODE-Solve to get ∂L/∂z(t0) and ∂L/∂θ;
		- ResNet: 6x residual blocks;
- FFJORD: W Grathwohl, et. al. ICLR'19
	- https://github.com/rtqichen/ffjord/
	- Insight: normalizing flow;
	- Formulation:
		- z0 = ∫t1..t0 f(z(t), t; θ)dt, z(t1)=x
		- logp(x)-logpz0(z0) = ∫t1..t0 -Tr(∂f/∂zt)dt, logp(x)-logp(zt1)=0
	- Implementation:
		- augment NODE (z) to (z, logpt), forward-backward OTD;
- ODE-RNN: Y Rubanova, R Chen, D Duvenaud. Latent ODEs for Irregularly-Sampled Time Series. NIPS'19
	- Insight: ODE-RNN hybrid; ODE during time steps; RNN update with new observation;
	- https://github.com/YuliaRubanova/latent_ode
	- Algorithm:
		- hi' = ODESolve(fθ, hi-1, (ti-1, ti)), to get ODE from ti-1 to ti
		- hi = RNNCell(hi', xi), update with new input
- ANODE: Augmented Neural ODEs. NIPS'19
	- https://github.com/EmilienDupont/augmented-neural-odes
	- Insight: ODE preserves topology and is not able to present some functions; augment to higher-dimension to make it possible;
		- E.g.1: f(1) = -1, f(-1) = 1; (cross each other)
		- E.g.2: two circles; (not linear separable)
	- Proposed method: augment with vector a;
		- d[h;a]/dt = f([h;a], t), with h(0)=x, a(0)=a
- ANODEV2: T Zhang, Z Yao, A Gholami, K Keutzer, J Gonzalez, G Biros, M Mahoney. ANODEV2: A Coupled Neural ODE Evolution Framework. NIPS'19
	- Insight: allow the network weight θ(t) to evolve with time;
		- z(1) = z(0) + ∫0..1 f(z(t), θ(t))dt
		- θ(t) = θ(0) + ∫0..1 q(z(θ(t), p)dt
- Acceleration:
	- HollowNet: T Chen, D Duvenaud. Neural Networks with Cheap Differential Operators. NIPS'19

## Learn Dynamics
- DeLaN: M Lutter, C Ritter, J Peters. Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning. ICLR'19
	- Notation:
		- T = q'H(q)q'/2: kinetic; H(q): symmetric positive definite;
		- V: potential with dV/dq=g(q);
		- τ: general force;
		- Then d(∂L/∂q')/dt-∂L/∂q=τ
	- Problem setup: estimate mass H(q) and force g(q);
		- Let H(q) = L(q;θ)L(q; θ)†, estimate L instead of H;
		- g(q) = g(q; ψ)
		- (θ; ψ) = argmin l(f(q,q',q'',θ,ψ), τ)
		- Supervision: l(.) any form s.t. Lagrange-eqn should hold;
	- Inverse: LL^Tq'' + d(LLT)/dt q' - 1/2 ∂(q'LL^Tq')/∂q + g
	- Application: learning an inverse dynamics model for robot control
- HNN: S Greydanus, M Dzamba, J Yosinski. Hamiltonian Neural Networks. NIPS'19
	- https://github.com/greydanus/hamiltonian-nn
	- Goal: learn a Hamiltonian to preserve energy;
		- Input p, q; learn H(p,q;θ) parametrized by MLP;
	- Supervision: estimated ∂H/∂p, ∂H/∂q and true dp/dt, dq/dt should match;
		- L = |∂H(θ)/∂p-∂q/∂t| + |∂H(θ)/∂q+∂p/∂t|
	- Pixel-HNN:
		- Input 2 frames to encode velocity;
		- Supervision: HNN loss + autoencoder-L2 + autoencoder-latent-space;
			- AE loss: latent z decode to get close to x;
			- Hamilton loss: z(t+1) close to estimated z(t)+M∂H/∂z
			- Conanical coord loss: Lcc = |zpt −(zqt −zqt+1)|, p is close to dq/dt.
- LNN: M Cranmer, S Greydanus, S Hoyer, P Battaglia, D Spergel, S Ho. Lagrangian Neural Networks. ICLR'20 Workshop
	- https://github.com/MilesCranmer/lagrangian_nns
	- Problem: given q, q', estimate dynamic q'';
		- Baseline NN: q'' = f(q, q')
		- LNN: estimate Lagrange L=f(q,q'), q''= (∂2L/∂q'2)^(-1)(∂L/∂q-q'∂2L/∂q∂q')
	- Background:
		- S = ∫(T(qt,q't)−V(qt)) dt
		- Many paths, physical system will take minimum δS = 0;
		- Denote: (∇q∇q'^T L)ij = ∂^2L/∂qi∂qj
		- d^2q/dt^2 = (∇q∇q'^T L)^-1 (∇qL-(∇q∇q'^T L)q')
	- Solving EL with JAX;
- SRNN: Z Chen, J Zhang, M Arjovsky, L Bottou. Symplectic Recurrent Neural Networks. ICLR'20
	- Insight: use a symplectic integrator (leapfrog):
		- pn+1/2 = pn − 1/2 ∆t V'(qn)
		- qn+1 = qn + ∆t K'(pn+1/2)
		- pn+1 = pn+1/2 − 1/2 ∆t V'(qn+1)
- N Gruver, M Finzi, S Stanton, A G Wilson. Deconstructing the Inductive Biases of Hamiltonian Neural Networks. ICLR'22
	- Insight: analyze why HNN outperforms NODE, with 3 reasons (energy cons, symplectic, 2nd-order)
	- HNN: dz/dt = J∇H, with J as antisymmetric matrix;
	- Reason 1 (Energy conservation): not the reason b/c numeric error accumulates;
		- dH(z)/dt = ∇H(z)dz/dt = ∇H J ∇H = 0 (b/c J antisymmetric)
	- Reason 2 (Symplectic vector Field): not the reason, symplectic regularization has negligible influence;
		- J matrix is preserved by the dynamics;
		- (JDF)'=JDF, b/c J=-J'
		- Vector field has 0 divergence: Tr(DF)=0
	- Reason 3 (2nd-order structure): main reason, acceleration directly
		- (dq/dt; dp/dt)=(M^-1(q)p; -dV/dq)
		- dq/dt = v
		- dv/dt = A(q, v)
	- Experiments: verified on Mojoco;

## Neural ODE
- Basics:
	- Neural net to approximate flow vector field and supervision at intermidiate/terminal time: NODE, ANODE;
	- Learn to predict dynamics with neural net for control: HNN;
- ODE-inspired network structure (continuous):
	- Sonoda, Sho and Murata, Noboru. Double continuum limit of deep neural networks. ICML Workshop'17
		- ∂φt(x)/∂t = ∇Vt(φt(x)), x ∈ R
		- φt(x) = x + ∫0..t ∇Vt(φt(x))ds, intractable
		- dµt/dt = −grad F(µt),
	- A Gholami, K Keutzer, G Biros. ANODE: Unconditionally Accurate Memory-Efficient Gradients for Neural ODEs. IJCAI'19
		- Insight: same formulation as NODE, a new solver to improve numeric stability;
		- Formulation: introduce adjoint α(t) as Lagrange, J(z1): loss at terminal;
			- L = J(z1, θ) + ∫0..1 α(t)(dz/dt-f(z,θ))dt
		- KKT:
			- ∂L/∂z = 0 (adjoint)
			- ∂L/∂θ = 0 (inversion)
			- ∂L/∂α = 0 (state)
		- OTD (Optimize then discritize) or DTO (Discretize Then Optimize)
		- ANODE:
			- Checkpointing: save activation; O(L)
	- **IMEXnet**: E Haber, K Lensink, E Treister, L Ruthotto. IMEXnet - A Forward Stable Deep Neural Network. ICML'19
		- Mix of explicit and implicit (forward/backward?)
		- dY/dt = f(Y, θ)+LY - LY; L: invertible matrix;
		- Yj+1 = (I+hL)^-1 (Yj + hLYj + hf(Yj,θj))
	- **LMU**: A Voelker, I Kajić, C Eliasmith. Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks. NIPS'19
		- https://github.com/abr/neurips2019
		- ODE-style cell: θdm(t)/dt = Am(t) + Bu(t)
		- ht = f(Wx xt + Wh ht-1 + Wm mt)
		- ut = ex xt + eh ht-1 + em mt-1
	- **DURR**: X Zhang, Y Lu, J Liu, B Dong. Dynamically Unfolding Recurrent Restorer: A Moving Endpoint Control Method for Image Restoration. ICLR'19
		- Insight: iterative optimization as a recurrent diffusion process; **terminal time is learned** from RL rather than a hyper-parameter;
		- https://i.buriedjet.com/projects/DURR/
		- https://github.com/BuriedJet/DURR/
		- Overall formulation: diffusion process parametrized with neural network;
			- min (L(X(T), y)+∫0..τ R(w(t),t)dt)
			- s.t. dX/dt=f(X(t), w(t)), X(0)=x
		- Restoration unit: at most 8 steps, separately learned; CNN-UNet;
		- Terminal time: learned with DQN;
			- min L=r(w)+Σi=1..d L(Xi,yi)
			- L(Xi,yi)=λ(Ln-1 - Ln)
		- Application: denoising;

## Neural PDE
- Generally 3 approaches:
	- Forward pathwise: memory O(1), time O(LD)
	- Backprop through solver: memory O(L), time O(L)
	- Stochastic adjoint (ours): memory O(1), time O(Llog L)
- **L-PDE**: C Fang, Z Zhao, P Zhou, and Z Lin. Feature learning via partial differential equation with applications to face recognition. PR'17.
	- Learned-PDE;
- PDE-inspired:
	- **PDE-Net**: Z Long, Y Lu, X Ma, B Dong. PDE-Net: Learning PDEs from Data. ICML'18
		- https://github.com/ZichaoLong/PDE-Net
		- Insight: two objectives at the same time:
			- To accurately predict **dynamics** of complex systems:
				- du/dt = F(x, y, u_x, u_y, u_xx, u_xy, u_yy, ...)
			- To uncover the underlying hidden PDE models (previous PDEs are human designed)
		- Architecture design:
			- One δt-block (not learned?):
				- u(t+1,.) = D0 u(u,.) + Δt F(x, y, D00u, D10u, D01u, D20u, D02u,...)
				- with D0, D00: average operators; D01,... approximate differential operators;
			- Multi δt-block (shared weights), with loss at each step;
		- Application: dicovering hidden PDE;
- Parabolic/hyperbolic CNNs, IMEX-Net; Lean ResNet;

## Neural SDE
- X Li, T L Wong, T Chen, D Duvenaud. Scalable Gradients for Stochastic Differential Equations. AISTATS'20
	- Insight: extend adjoint to **SDE**;\
		<img src = '/DL/images/dynamic-system/sde-adjoint.png' width = '400'>
- J Jia and A Benson. Neural Jump Stochastic Differential Equations. arxiv'19
- X Liu, S Si, Q Cao, S Kumar, and C Hsieh. Neural sde: Stabilizing neural ode networks with stochastic noise. arxiv'19
- B Tzen and M Raginsky. Neural stochastic differential equations: Deep latent gaussian models in the diffusion limit. arxiv'19
- B Tzen and M Raginsky. Theoretical guarantees for sampling and inference in generative models with latent diffusions. COLT'19

## ML-Solver
- Use ML (could be neural net) to solve a given ODE/PDE;
- General:
	- I Lagaris, A Likas, and D Fotiadis. Artificial neural networks for solving ordinary and partial differential equations. TNN'98
- ODE Solver:
	- Nguyen, B. D., and McMechan, G. A. Five ways to avoid storing source wavefield snapshots in 2d elastic prestack reverse time migration. Geophysics'14
		- Reversible numerical methods for ODEs have been studied in the context of hyperbolic differential equations;
	- M Schober, D Duvenaud, P Hennig. Probabilistic ODE solvers with Runge-Kutta means. NIPS 2014
		- Gaussian Process to solve ODE
	- W E. A proposal on machine learning via dynamical systems. Communications in Mathematics and Statistics. 2017
		- Insight: first proposed connection between ResNet and ODE; ResNet = Forward Euler;
	- M Raissi, P Perdikaris, George Em Karniadakis. Multistep neural networks for data-driven discovery of nonlinear dynamical systems. 2018
		- https://github.com/maziarraissi/MultistepNNs
		- Insight: fit a neural model to approximate dynamics;
		- To model dx/dt=g(x), apply a neural net f(x, θ), s.t.
			- yn = ∑ α(m)x(n−m) + ∆t β(m)f(x(n−m))
			- Loss with MSE on y;
- PDE solver:
	- B Dong, Q Jiang and Z Shen. Image restoration: wavelet frame shrinkage, nonlinear evolution pdes, and beyond. Multiscale Modeling & Simulation'17
		- Insight: Conv operator as differentiation;
	- Rassi. Numerical Gaussian processes for time-dependent and nonlinear partial differential equations. 2018

## Dynamic Equilibrium, Fixed Point
- Insight:
	- zt+1 = f(zt, x:1:T; θ) until convergence (equilibrium condition);
	- Directly solve for the fixed point rather than iterating;
	- How to differentiate fixed point w.r.t. θ: dz/dθ (implicit function theorem)
- Legacy:
	- **Almeida-Pineda** algorithm;
		- Almeida, L. B. A learning rule for asynchronous perceptrons with feedback in a combinatorial environment. ICNN'87
		- Pineda, F. J. Generalization of back-propagation to recurrent neural networks. Physical review letters'87
	- P Simard, M Ottaway, and D Ballard. Fixed point analysis for recurrent networks. NIPS'89
	- B Cessac. A view of neural networks as dynamical systems. International Journal of Bifurcation and Chaos. 2010
- J Miller and M Hardt. When recurrent models don't need to be recurrent. arXiv'18
- **RBP**: R Liao, Y Xiong, E Fetaya, L Zhang, K Yoon, X Pitkow, R Urtasun, R Zemel. Reviving and Improving Recurrent Back-Propagation. ICML'18
	- Insight: consider a class of RNNs whose **hidden state** converges to a steady state, with **Implicit Function Theorem**;
	- https://github.com/lrjconan/RBP
	- Fix point of Ψ w.r.t. h: Ψ(w,h) = h - F(x, w, h)
		- ∂Ψ/∂w = ∂h/∂w - dF/dw = (I-∂F/∂h)∂h/∂w - ∂F/∂w = 0, at equilibrium h;
	- Derivative of output, y=G(x,wG,h) and loss L(y,yGT);
		- ∂L/∂w = ∂L/∂y ∂G/∂w
		- ∂L/∂w = ∂L/∂y ∂y/∂h (I-∂F/∂h)^-1 ∂F/∂w
	- original RBP (Pineda 1987; Almeida, 1987) introduce auxiliary var z:
		- z = (I-∂F/∂h)^-1 (∂L/∂y ∂y/∂h)T
	- RBP algorithm:
		- Iteratively update z until z converges: |zi - zi-1| < ε
	- **CG-RBP**: conjugate gradient on normal equations:
		- (I-∂F/∂h)(I-∂F/∂h)T z = (I-∂F/∂h)(∂L/∂y ∂y/∂h)^T
	- Neumann series (Neumann-RBP): sum(I+A+A^2+...) Neumann series, truncated at K:
		- g = (I+J+J^2+...+J^K)v
		- ∂L/∂w = gT ∂F/∂w
- **DEQ**: S Bai, Z Kolter, V Koltun. Deep Equilibrium Models. NIPS'19
	- https://github.com/locuslab/deq
	- Insight: given input x1:T, an RNN-cell iterate z1:T=f(z1:T, x:1:T; θ) with indinite depth:
		- Directly solve for fixed point z'=f(z', x:1:T; θ)
	- Theorem of backprop through fixed point:
- Equilibrium Propagation
	- B. Scellier and Y. Bengio. Towards a biologically plausible backprop. arXiv'16
	- B. Scellier and Y. Bengio. Equilibrium propagation: Bridging the gap between energy-based models and backpropagation. 2017
		- A biologically inspired equilibrium propagation framework for an energy-based model whose prediction is the fixed-point of the energy dynamics at its local minimum;
	- B. Scellier and Y. Bengio. Equivalence of equilibrium propagation and recurrent backpropagation. NC'19
	- M Ernoult, J Grollier, D Querlioz, Y Bengio, B Scellier. Updates of Equilibrium Prop Match Gradients of Backprop Through Time in an RNN with Static Input. NIPS'19
		- https://github.com/ernoult/updatesEPgradientsBPTT
