# Control and Planning

## Sergey Levine
- MCTS (lec-10)

## Monte-Carlo Tree Search
- Approach
<img src="/RL/images/mcts.png" alt="drawing" width="500"/>

- Legacy
	- C. Browne, E. Powley, D. Whitehouse, S. Lucas, P. I. Cowling, P. Rohlfshagen, D. P. Stephen Tavener, S. Samothrakis, and S. Colton. A survey of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in Games, 2012
	- S. Gelly and D. Silver. Combining online and offline knowledge in uct. ICML, 2007.
	- L. Kocsis and C. Szepesvàri. Bandit based monte-carlo planning. ECML, 2006.
	- Rémi Coulom. Efficient selectivity and backup operators in monte-carlo tree search. In International conference on computers and games, pages 72–83. Springer, 2006.
	- G. Tesauro and G. R. Galperin. On-line policy improvement using monte-carlo search. NIPS'96.
- New, SOA
	- X. Guo, S. Singh, H. Lee, R. Lewis, and X. Wang. Deep learning for real-time atari game play using offline monte-carlo tree search planning. NIPS'14
		- Imitation learning from MCTS
	- Thomas Anthony, Zheng Tian, and David Barber. Thinking fast and slow with deep learning and tree search, 2017.

## SOA
- Memory-based control with recurrent neural networks
- Model-Free Episodic Control
- TREEQN AND ATREEC: DIFFERENTIABLE TREE PLANNING FOR DEEP REINFORCEMENT LEARNING
- A Controller-Recognizer Framework: How necessary is recognition for control?
- Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning

## Planning
- The Predictron: End-To-End Learning and Planning, ICML 2017

## Physics
- Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics

## Theory
- On the Sample Complexity of the Linear Quadratic Regulator

## Legacy
- Proto-value Functions: A Laplacian Framework for Learning Representation and Control in Markov Decision Processes, 2007
