# Meta-RL

## From Spinningup
- RL2, l2rl, MAML, SNAIL;

## DeepMind
- **L2RL**: J X Wang, Z Kurth-Nelson, D Tirumala, H Soyer, J Z Leibo, R Munos, C Blundell, D Kumaran, M Botvinick. Learning to reinforcement learn. CogSci 2016
- S Ritter, J X. Wang, Z Kurth-Nelson, S M. Jayakumar, C Blundell, R Pascanu, M Botvinick. Been There, Done That: Meta-Learning with Episodic Recall. ICML'18
- Z Xu, H van Hasselt, D Silver. Meta-Gradient Reinforcement Learning. NIPS'18
- M Botvinick, S Ritter, J X. Wang, Z Kurth-Nelson, C Blundell, D Hassabis. Reinforcement Learning, Fast and Slow. Trends in Cognitive Sciences 2019 

## OpenAI
- **RL2**: Y Duan, J Schulman, X Chen, P Bartlett, I Sutskever, P Abbeel. RL2: Fast Reinforcement Learning via Slow Reinforcement Learning. 2016
	- Fast RL: learned "algorithm" performed by LSTM
	- Slow RL: algorithm used to train LSTM in outer loop
- I Clavera, J Rothfuss, J Schulman, Y Fujita, T Asfour, P Abbeel. Model-Based Reinforcement Learning via Meta-Policy Optimization. CoRL'18
- A Nichol, J Achiam and J Schulman. On First-Order Meta-Learning Algorithms. 2018

## Berkeley
- **MAML**:
	- MAML for RL: https://github.com/cbfinn/maml_rl
- **SNAIL**: A Simple Neural Attentive Meta-Learner, Mishra et al, 2018.

## Unclassified
- Berkeley. The Importance of Sampling in Meta-Reinforcement Learning. NIPS'18
- Sergey. Meta-Reinforcement Learning of Structured Exploration Strategies. NIPS'18
- Zero-Shot Transfer with Deictic Object-Oriented Representation in Reinforcement Learning. NIPS'18
