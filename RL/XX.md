# Exploration, Exploitation

## Sergey Levine
- MCTS (lec-17)
- UCB
<img src="/RL/images/xx-ucb.png" alt="drawing" width="500"/>

- **Thompson Sampling**: O Chapelle, L Li. An Empirical Evaluation of Thompson Sampling, NIPS'11

- Information Gain: D Russo, B V Roy. Learning to Optimize via Information-Directed Sampling. NIPS'14
<img src="/RL/images/xx-ig.png" alt="drawing" width="500"/>

- Summary
<img src="/RL/images/xx-sum.png" alt="drawing" width="500"/>

## Multi-Arm Bandit
- http://iosband.github.io/2015/07/28/Beat-the-bandit.html
- https://github.com/bgalbraith/bandits

## SOA
- Deep Exploration via Bootstrapped DQN, 2016
- OpenAI: VIME: Variational Information Maximizing Exploration 2017
- INCENTIVIZING EXPLORATION IN REINFORCEMENT LEARNING WITH DEEP PREDICTIVE MODELS
- Skip Context Tree Switching
- DeepMind, Unifying Count-Based Exploration and Intrinsic Motivation, 2016
- OpenAI, EX2: Exploration with Exemplar Models for Deep Reinforcement Learning, NIPS 2017
- #Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning

## Curiosity
- Deepak Pathak: TensorFlow code for Curiosity-driven Exploration for Deep Reinforcement Learning, ICML 2017
	- https://github.com/pathak22/noreward-rl
- Imagination-Augmented Agents for Deep Reinforcement Learning

## Explore-Go
- Montezumaâ€™s Revenge Solved by Go-Explore, a New Algorithm for Hard-Exploration Problems (Sets Records on Pitfall, Too)
	- https://eng.uber.com/go-explore/

## Legacy
- 1992 A Possibility for Implementing Curiosity and Boredom in Model-Building Neural Controllers