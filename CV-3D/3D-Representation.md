# 3D Data as Output (Objects)

## Basics
- Representations:
	- Point clouds;
	- Voxel;
	- Mesh;
	- Oct-tree;
	- Templates: Primitives; Implicit functions;
	- Depth; 2.5D;
	- Important task: fusion; (KinectFusion, ...)
- Supervision and Evaluation:
	- Geometry:
		- **Chamfer distance**: H. G. Barrow, J. M. Tenenbaum, R. C. Bolles, and H. C. Wolf. Parametric Correspondence and Chamfer Matching: Two New Techniques for Image Matching. IJCAI'77
			- Sum of closest point distances
			- Asymmetric
			- For Hausdorff distance, simply a distance transform?
		- EMD;
	- Photometric;
- 3D reconstruction:
	- Direct 3D reconstruction for whole object;
	- Scene: depth map;
	- Infer cues:
		- 2.5-D: - H. G. Barrow and J. M. Tenenbaum, Recovering intrinsic scene characteristics from images, Computer Vision Systems, 1978

## 1. Point Cloud
- Basics:
	- Directly map from latent space z to nx3 dim as n points; (most AE)
	- Fold a 2D surface/rectangle (folding net)
	- Deform a Gaussian ball (CNF, pointflow)
- **PSGN**: H Fan, H Su, and L Guibas. A point set generation network for 3d object reconstruction from a single image. CVPR'17
	- Key insight: hourglass better; random variable;
	- https://github.com/fanhqme/PointSetGeneration
	- Input: image, random variable r; output: point cloud;
	- Net-structure: encoder, predictor;
	- Supervision: 1. Chamfer distance; 2. EMD with approximation;
	<img src="/CV-3D/images/3d_output/point-set-gen.png" alt="drawing" width="600"/>
- Nobuyuki Umetani. Exploring Generative 3D Shapes Using Autoencoder Networks. SIGGRAPH Asia'17
	- AutoEncoder on 3D points and hand-coded features;
- **AAE**: Maciej Zamorski, Maciej Zieba, Rafał Nowak, Wojciech Stokowiec, and Tomasz Trzciński. Adversarial autoencoders for generating 3d point clouds. 2018
	- Build on Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. Adversarial autoencoders. 2015
- Chen-Hsuan Lin, Chen Kong, and Simon Lucey. Learning efficient point cloud generation for dense 3d object reconstruction. AAAI'18
- Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas Guibas. Learning representations and generative models for 3d point clouds. ICML'18
	- Input/output: point cloud;
	- AE, x -> z=f(x) -> x'
	- Supervision: Chamfer(x, x')
- **FoldingNet**: Y. Yang, C. Feng, Y. Shen, and D. Tian. Foldingnet: Interpretable unsupervised learning on 3d point clouds. CVPR'18
	- https://www.merl.com/research/license#FoldingNet
	- AE
	- Encoder: MLP + graph-based matrix pooling; output a 512 x 1 dim feature;
		- Graph: K-NN graph, 3 (xyz) + 9 (covariance) = 12-dimension; (local pooling like PointNet++)
	- Decoder: takes 512-dim feature and fixed 2D grid, fold; m x 514-dim input; 512d + xy;
		- MLP;
- Matheus Gadelha, Rui Wang, and Subhransu Maji. Multiresolution tree networks for 3d point cloud processing. ECCV'18
	- VAE
- Chun-Liang Li, Manzil Zaheer, Yang Zhang, Barnabas Poczos, and Ruslan Salakhutdinov. Point cloud gan. ICLR'19
	- Theoretical paper: derive WGAN-style divergence for point set;
	- Experiment: built on AE
- Diego Valsesia, Giulia Fracastoro, and Enrico Magli. Learning localized generative models for 3d point clouds via graph convolution. ICLR'19
- Ruihui Li, Xianzhi Li, Chi-Wing Fu, Daniel Cohen-Or, and Pheng-Ann Heng. PU-GAN: A point cloud upsampling adversarial network. ICCV'19
- **CNF**:
	- **Pointflow**: Guandao Yang, Xun Huang, Zekun Hao, Ming-Yu Liu, Serge Belongie, and Bharath Hariharan. Pointflow: 3d point cloud generation with continuous normalizing flows. ICCV'19
		- CNF based model;
	- Shitong Luo, Wei Hu. Diffusion Probabilistic Models for 3D Point Cloud Generation. CVPR'21
		- https://github.com/luost26/diffusion-point-cloud
		- MCMC
- Dong Wook Shu, Sung Woo Park, and Junseok Kwon. 3d point cloud generative adversarial network based on tree structured graph convolutions. ICCV'19

## 2. Voxel
- Basics:
	- Input: 3D (AE), image (reconstruction), partial (inpainting), ... encoder to z;
	- Then z back to complete shape;
	- With camera parameter: unproject/ray tracing in 3D-Conv;
	- Supervision:
		- Strong: Direct 3D occupancy;
		- Weak: Indirect 2D rendering consistency, or Inverse Graphics;
	- Handle multiple inputs:
		- Carving to satisfy multiple constraint;
		- CNN-RNN (problem: not order-invariant);
		- Fusion network;
- Legacy (Non-DL):
	- **Voxlet**: Michael Firman, Oisin Mac Aodha, Simon Julier, Gabriel J. Brostow. Structured Prediction of Unobserved Voxels From a Single Depth Image. CVPR'16
		- https://github.com/mdfirman/voxlets
		- Input depth image (no-rgbd), output voxel binary occupancy;
		- Model: structured random forest;
- 3D-Deconv from latent space:
	- Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3d shapenets: A deep representation for volumetric shapes. CVPR'15
		- Input: image; output: voxel;
	- **3D-R2N2**: Christopher B. Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, Silvio Savarese. 3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction. ECCV'16
		- https://github.com/chrischoy/3D-R2N2
		- Input: single/multiple images; output: voxel;
		- Model:
			- CNN-RNN: CNN (ResNet), RNN to update model with RNN each time with a new image;
			- RNN: no output gates, only output at final;
		- Supervision: binary cross-entropy on the final output;
		<img src="/CV-3D/images/3d_output/3d-r2n2.png" alt="drawing" width="500"/>
	- R Girdhar, D F Fouhey, M Rodriguez, and A Gupta. Learning a predictable and generative vector representation for objects. ECCV'16
		- Problem definition: AE
		- Input: Voxel, image; Output: voxel;
		- Model:
			- Encoder: concatenate of features conv3d for voxel, conv2d for image;
			- Decoder: 3D-deconv;
	- Danilo Jimenez Rezende, SM Eslami, Shakir Mohamed, Peter Battaglia, Max Jaderberg, and Nicolas Heess. Unsupervised learning of 3d structure from images. NIPS'16
		- Key insight: **c-VAE** style;
		- Input: single image/voxel;
		- Supervision: 2D-weak-sup; REINFORCE to bypass back-prop through black-box renderer;
		- Experiment: ShapeNet;
		<img src="/CV-3D/images/3d_output/unsup-3d.png" alt="drawing" width="600"/>
	- Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum. Learning a probabilistic latent space of object shapes via 3d generative adversarial modeling. NIPS'16
		- GAN / GAN-VAE;
		- Noisy / Blurry;
	- Andrew Brock, Theodore Lim, James M Ritchie, and Nick Weston. Generative and discriminative voxel modeling with convolutional neural networks. 3D Deep Learning Workshop at NIPS'16
		- VAE;
		- https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling
	- **HSP**: C Hane, S Tulsiani, J Malik. Hierarchical Surface Prediction for 3D Object Reconstruction. 3DV'17
		- Insight: **coarse to fine**, 16^3 to 32^3 to ... 256^3; only nodes on boundary needs upsamplng;
		- https://github.com/chaene/hsp
		- Input: color, depth, partial volume; Ouptut: voxel (3 classes: free, **boundary**, occupied)
		- CNN with deep-supervision on different resolution
		- Most important part: predict layer l+1 based on layer l (e.g. from 16^3 to 32^3)
			- 1. Feature Cropping: (b/2+2p)^3 region with p padding;
			- 2. Upsampling: (b+2p)^3 region
			- 3. Output generation: max boundary prediction reponse; above threshold, expand child;
		<img src="/CV-3D/images/3d_output/factor3d.png" alt="drawing" width="600"/>
	- **PrGAN**: Matheus Gadelha, Subhransu Maji and Rui Wang. 3D Shape Induction from 2D Views of Multiple Objects. 3DV'17
		- https://github.com/matheusgadelha/PrGAN
		- Input: latent code 200-dim;
		- Backbone: 3d-deconv;
		- Supervision: weak-supervised, project to 2D then a discriminator;
	- D. Stutz and A. Geiger. Learning 3D shape completion from laser scan data with weak supervision. CVPR'18
		- Problem: 3D completion;
		- Model:
			- Step 1: VAE y -> y'
			- Step 2: keep the decoder, train an encoder to map partial data to the same latent space;
	- Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or, and H. Huang. SAGNet: Structure-aware generative network for 3d-shape modeling. TOG'19
		- GRU + VAE;
- **Unproject** from 2D (assume known camera pose?):
	- A. O. Ulusoy, A. Geiger, and M. J. Black. Towards probabilistic volumetric reconstruction using ray potentials. 3DV'15
	- **PTN**: X Yan, J Yang, E Yumer, Y Guo, and H Lee. Perspective transformer nets: Learning single-view 3d object reconstruction without 3d supervision. NIPS'16
		- Insight: encoder-decoder for 2d-3d, no 3d supervision, silhouette supervision from different views instead of gt;
		- https://github.com/xcyan/ptnbhwd
		- Input: image; output: voxel;
		- Assumption: clean background;
		- Encoder-decoder: view-invariant encoder for image h(I), decoder generates 3d v=g(h(I));
		- Supervision: silhouette-based volumetric loss from space carving;
		<img src="/CV-3D/images/3d_output/per-trans-net.png" alt="drawing" width="600"/>
	- J. Gwak, C. B. Choy, M. Chandraker, A. Garg, and S. Savarese. Weakly supervised 3d reconstruction with adversarial constraint. 3DV'17
		- Input: multiple images;
		- Backbone: CNN-RNN;
		- Final output ray-trace pooling to get 2D projection;
		- Supervision: adversarial with 3d shapes;
	- **Surfacenet**: Ji, M., Gall, J., Zheng, H., Liu, Y., Fang, L. Surfacenet: An end-to-end 3d neural network for multiview stereopsis. ICCV'17
		- Insight: end-to-end multi-view stereo; geometry with color encoded in voxel with **unproject**;
		- https://github.com/mjiUST/SurfaceNet
		- Input: images with camera pose; Output: 3D voxel, with [0,1] for on surface or not;
		- Turn images to CVC (color voxel cube)\
		<img src="/CV-3D/images/3d_output/surface-net1.png" alt="drawing" width="350"/>
		<img src="/CV-3D/images/3d_output/surface-net2.png" alt="drawing" width="350"/>
	- **LSM**: A. Kar, C. Häne, J. Malik. Learning a multi-view stereo machine. NIPS'17
		- https://github.com/akar43/lsm
		- Input: multiple images; Output: 32^3 Voxel 3D;
		- Assumption: **camera pose known**;
		- Cost volume; \
		<img src="/CV-3D/images/stereo/lsm1.png" alt="drawing" width="500"/>
		<img src="/CV-3D/images/stereo/lsm2.png" alt="drawing" width="500"/>
	- **MVC**: S Tulsiani, A Efros, J Malik. Multi-view Consistency as Supervisory Signal for Learning Shape and Pose Prediction. CVPR'18
		- Key insight: **unknown-shape**, 
		- https://github.com/shubhtuls/mvcSnP
		- Input: single image; output: camera pose, 3D-shape;
		- Training mode: (two images of an object as input)
			- Shape from first view; (conanical view?)
			- Pose from second view;
		- Test mode: independent shape and pose;
		<img src="/CV-3D/images/3d_output/mvc.png" alt="drawing" width="600"/>
	- Stephan R. Richter and Stefan Roth. Matryoshka networks: Predicting 3d geometry via nested shape layers. CVPR'18
		- Input: image, camera pose;
		- Voxel tube: input 2D feat nt x nt x f, finally get 3D no x no x no;
		- Shape layer: efficiently compress voxel tubes: record enter and exit shape;
		- Nested shape layers: similar to CSG? (handle image input one by one like Matryoshka doll)
	- **DRC**: S Tulsiani, T Zhou, A Efros, J Malik. Multi-view Supervision for Single-view Reconstruction via Differentiable Ray Consistency.  PAMI'19
		- Key insight: relax 3D GT requirement to 2D consistency!
		- https://github.com/shubhtuls/drc (torch);
		- Input: image (model) + multiple images (refine?); Output: voxel for 3d;
		- Model: ray termination event;	Event: a ray intersect a voxel, previous voxels are all unoccupied
		- Supervision:
			- Depth, Foreground mask
			- Per-ray consistency loss
		- Experiment: ShapeNet; PASCAL 3D
		<img src="/CV-3D/images/3d_output/drc.png" alt="drawing" width="600"/>
	- Edward Smith, Scott Fujimoto, David Meger. Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation. NIPS'18
		- https://github.com/EdwardSmith1884/Multi-View-Silhouette-and-Depth-Decomposition-for-High-Resolution-3D-Object-Representation
		- Main insight: high-resolution (512 x 512 x 512);
		- Input: 2D image or 3D low-res voxel;
		- Model:
			- Representation: six axis-aligned orthographic depth maps (ODM);
				- Super-resolve the ODM;
			- 3D model carving: use high-res ODM to update 3D-voxel;
	- **SATNet**: Shice Liu, YU HU, Yiming Zeng, Qiankun Tang, Beibei Jin, Yinhe Han, Xiaowei Li. See and Think: Disentangling Semantic Scene Completion. NIPS'18
		- https://github.com/ShiceLiu/SATNet
		- Input: 2D image/depth map;
		- Model: 3 components;
			- SNet: 2D Semantic Segmentation
			- 2D-3D Reprojection Layer: given depth, sem label, intrinsic, extrinsic, unproject to get voxel as D x Sx x Sy x Sz;
			- TNet: 3D Semantic Scene Completion;
	- Haozhe Xie, Hongxun Yao, Xiaoshuai Sun, Shangchen Zhou, and Shengping Zhang. Pix2vox: Context-aware 3d reconstruction from single and multi-view images. ICCV'19
		- https://infinitescript.com/project/pix2vox/
		- Insight: Fusion of different 3D voxel with **context-aware-fusion network**;
			- Select confident (seen) parts from each image;
		- Refiner net to super-resolve;
- Oct-Tree:
	- **OGN**: Maxim Tatarchenko, Alexey Dosovitskiy, and Thomas Brox. Octree generating networks: Efficient convolutional architectures for high-resolution 3d outputs. ICCV'17
		- Key: **Coarse to fine**;
		- https://github.com/lmb-freiburg/ogn
		- Input: image; output: voxel;
		<img src="/CV-3D/images/3d_output/ogn.png" alt="drawing" width="600"/>
	- Gernot Riegler, Ali Osman Ulusoy, Horst Bischof, and Andreas Geiger. Octnetfusion: Learning depth fusion from data. 3DV'17
	- **Adaptive O-CNN**: Peng-Shuai Wang, Chun-Yu Sun, Yang Liu, and Xin Tong. Adaptive O-CNN: a patch-based deep representation of 3d shapes. SIGGRAPH Asia'18
- From other info:
	- **GenRe**: X Zhang, Z Zhang, C Zhang, J Tenenbaum, W Freeman and J Wu. Learning to Reconstruct Shapes from Unseen Classes. NIPS'18
		- Insight: project to spherical map;
		- Input: single image;
		- https://github.com/xiumingzhang/GenRe-ShapeHD
		<img src="/CV-3D/images/3d_output/genre.png" alt="drawing" width="600"/>

## 3. Mesh
- Legacy:
	- Voronoi diagram;
	- Delaunay triangulation;
- Legacy: Marching Cubes;
	- Given function defining +/- as outside inside, output the surface (mesh);
	- Insight: go through each cube independently, lookup table (2 ^ 8 = 256 cases), handle the surface accordingly by lookup, adapt to find a better surface;
	- http://www.cs.carleton.edu/cs_comps/0405/shape/marching_cubes.html
	- **Marching cubes**: W. E. Lorensen and H. E. Cline. Marching cubes: A high resolution 3d surface construction algorithm. SIGGRAPH'87
		- Input: mask; output: mesh triangulation;
	- https://www.boristhebrave.com/2018/04/15/marching-cubes-tutorial/
	- https://www.boristhebrave.com/2018/04/15/marching-cubes-3d-tutorial/
	- https://github.com/BorisTheBrave/mc-dc
- Legacy: **Poisson Surface Reconstruction**
	- Input: given **discrete** points with known **oriented normals**, construct continuous watertight surface with **implicit function** that best match the normal;
		- Image the function is defined on the 3D space as
			- f(x) = 0 outside
			- f(x) = 1 inside;
			- grad(f(x)) oriented normals on surface;
			- Goal: get f(x) everywhere;
			- Smoothing (convolve with Gaussian kernel);
			- grad(f(x)) = smoothed (normal)
			- Min square solution: Laplacian(f(x)) = grad (normal)
			- To get f(x): marching cube on the oct-tree;
	- M. M. Kazhdan, M. Bolitho, and H. Hoppe. Poisson surface reconstruction. SGP'06
	- M. M. Kazhdan and H. Hoppe. Screened poisson surface reconstruction. SIGGRAPH'13
- Legacy: deform an initial mesh;
	- Similar to active-contour, leads to local minima;
	- Andrei Sharf, Thomas Lewiner, Ariel Shamir, Leif Kobbelt, and Daniel Cohen-Or. 2006. Competing fronts for coarse–to–fine surface reconstruction. CGF'06
- Legacy:
	- Hugues Hoppe. Progressive meshes. SIGGRAPH'96
	- F. Bernardini, J. Mittleman, H. Rushmeier, C. Silva, and G. Taubin. The ball-pivoting algorithm for surface reconstruction. TVCG'99
	- F. Calakli and G. Taubin. SSD: smooth signed distance surface reconstruction. CGF'11
- Direct mesh by downsample, upsample:
	- Qingyang Tan, Lin Gao, Yu-Kun Lai, Jie Yang,and Shihong Xia. Mesh-based autoencoders for localized deformation component analysis. AAAI'18
		- https://github.com/aldehydecho/convMesh
	- Qingyang Tan, Lin Gao, Yu-Kun Lai, and Shihong Xia. Meshvae: Variational autoencoders for deforming 3d mesh models. CVPR'18
	- **Coma**: A. Ranjan, T. Bolkart, S. Sanyal, and M. J. Black. Generating 3D faces using convolutional mesh autoencoders. ECCV'18
		- https://coma.is.tue.mpg.de/
	- **MeshCNN**: Rana Hanocka, Amir Hertz, Noa Fish, Raja Giryes, Shachar Fleishman, Daniel Cohen-Or. MeshCNN: A Network with an Edge. SIGGRAPH'19
		- https://ranahanocka.github.io/MeshCNN/
		- https://github.com/ranahanocka/MeshCNN/
		- https://docs.google.com/presentation/d/1yLZ6uyAujyF0MtFWofAMFgWQpWaDYqS8vkdge_lzk6g/edit#slide=id.g35f391192_00
		- Insight: edges + affinity from meshes;
		- Mesh-Conv:\
			<img src="/CV-3D/images/3d_output/mesh-conv.png" alt="drawing" width="400"/>
		- Mesh-Pool: remove edges to collapse (5 edges -> 2)\
			<img src="/CV-3D/images/3d_output/mesh-pool-1.png" alt="drawing" width="400"/>
			<img src="/CV-3D/images/3d_output/mesh-pool-2.png" alt="drawing" width="400"/>
		- Mesh-Unpool:\
			<img src="/CV-3D/images/3d_output/mesh-unpool.png" alt="drawing" width="400"/>
- Deformation-based:
	- DeformNet: A Kuryenkov, J Ji, A Garg, V Mehta, J Gwak, C Choy, S Savarese. DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction from a Single Image. 2017
		- Check CAD/template-based method;
	- Q Tan, L Gao, Y Lai, J Yang and S Xia. Mesh-based Autoencoders for Localized Deformation Component Analysis. 2017
		- AutoEncoder;
		- Input: multiple mesh; output: new mesh synthesis (deformation);
		- Point feature: manually designed;
		- Encoder: GCN;
		- Decoder: mirrored encoder?
	- **cmr**: Angjoo Kanazawa, Shubham Tulsiani, Alexei A Efros, and Jitendra Malik. Learning category-specific mesh reconstruction from image collections. ECCV'18
		- https://github.com/akanazawa/cmr
		- Input: image; Output mesh;
		- Model:
			- Encoder: image -> 2D-CNN to get latent feature shared by three output modules;
			- Output: 1. camera pose; 2. deformation for each vertice; 3. texture;
		- Supervision: mask + keypoitn + texture;
		<img src="/CV-3D/images/3d_output/cmr.png" alt="drawing" width="550"/>
	- **Pixel2mesh**: Nanyang Wang, Yinda Zhang, Zhuwen Li, Yanwei Fu, Wei Liu, and Yu-Gang Jiang. Pixel2mesh: Generating 3d mesh models from single rgb images. ECCV'18
		- GCN to deform a ball; unpool to add more nodes and edges;
		- CD for supervision;
		- https://github.com/nywang16/Pixel2Mesh
		<img src="/CV-3D/images/3d_output/pixel2mesh-1.png" alt="drawing" width="500"/>
		<img src="/CV-3D/images/3d_output/pixel2mesh-2.png" alt="drawing" width="500"/>
	- **Geometrics**: Edward J Smith, Scott Fujimoto, Adriana Romero, and David Meger. Geometrics: Exploiting geometric structure for graph-encoded objects. ICML'19
		- https://github.com/EdwardSmith1884/GEOMetrics
	- **Pixel2mesh++**: Chao Wen, Yinda Zhang, Zhuwen Li, and Yanwei Fu. Pixel2mesh++: Multi-view 3d mesh generation via deformation. ICCV'19
		- https://github.com/walsvid/Pixel2MeshPlusPlus
		- Extension of Pixel2mesh;
		- First Pixel2mesh to get a coarse mesh;
		- Then iterative module to refine by multi-view with GCN;
	- **Mesh R-CNN**: Georgia Gkioxari, Jitendra Malik, and Justin Johnson. Mesh R-CNN. ICCV'19
		- https://gkioxari.github.io/meshrcnn/
		- https://github.com/facebookresearch/meshrcnn
		- Problem setup: input single image, output a set of detected object instances, with a triangle mesh for each object.
		- Approach: Mask R-CNN, coarse voxel (initial mesh), mesh refinement;
			<img src="/CV-3D/images/3d_output/mesh-rcnn.png" alt="drawing" width="600"/>
		- Lift to 3D: w x h G-channel;
		- Cubify: voxel to triangular mesh (8 vertices, 18 edges, 12 faces); merge shared edges and vertices; eliminate interior ones;
		- Mesh refinement (similar to **Pixel2mesh**):
			- 1. vertex alignment, which extracts image features for vertices; (with camera intrinsic)
			- 2. graph convolution, which propagates information along mesh edges;
			- 3. vertex refinement， which updates vertex positions.
		- Supevision: similar to **Geometrics**; sample points, Chamfer-Distance;
	- Charlie Nash, Yaroslav Ganin, S. M. Ali Eslami, and Peter W. Battaglia. PolyGen: An autoregressive generative model of 3d meshes. ICML'19
		- https://github.com/deepmind/deepmind-research/tree/master/polygen
		- **Transformer** on points and faces;
	- CAD-Deform: Vladislav Ishimtsev, Alexey Bokhovkin, Alexey Artemov, Savva Ignatyev, Matthias Niessner, Denis Zorin. CAD-Deform: Deformable Fitting of CAD Models to 3D Scans. ECCV'20
		- Energy-based;
		- https://github.com/alexeybokhovkin/CAD-Deform
- Mesh from other representations (with differentiable op):
	- Y. Liao, S. Donne, and A. Geiger. Deep marching cubes: Learning explicit surface representations. CVPR'18
		- Differentiable Marching Cubes;
	- **NMC**: Zhiqin Chen and Hao Zhang, Neural Marching Cubes. TOG'21
		- https://github.com/czq142857/NMC
- Piecewise surface:
	- **AtlasNet**. T. Groueix, M. Fisher, V. G. Kim, B. C. Russell, and M. Aubry. Atlasnet: A papier-mache approach to learning 3d surface generation. CVPR'18
		- https://github.com/ThibaultGROUEIX/AtlasNet
		- Input point cloud or image encoded by a NN as feature f(x)
		- Then, f(x) and points sampled on a rectangle reconstruct an atlas on shape x;
			- Multiple MLP for multiple patches (Atlas);
- Mesh from point cloud;
	- **DGP**: Francis Williams, Teseo Schneider, Claudio Silva, Denis Zorin, Joan Bruna, and Daniele Panozzo. Deep geometric prior for surface reconstruction. CVPR'19
		- Similar to deep-image-prior;
	- Rana Hanocka, Gal Metzer, Raja Giryes, Daniel Cohen-Or. Point2Mesh: A Neural Self-Prior for Deformable Meshes. SIGGRAPH'20
		- Insight: coarse-to-fine MeshCNN:
			<img src="/CV-3D/images/3d_output/point2mesh.png" alt="drawing" width="500"/>
		- Loss: Mesh to Point Cloud Distance: Chamfer + differentiable sampler;
		- Loss: Beam-gap loss: to handle narrow deep cavity;
		- Implementation: iterative for K=1000 iterations by network, then pass to RWM [Huang'18] to generate manifold, watertight and non-interscting surface;
		- Runtime (per iteration): 0.23/0.59/4.7 sec on 2k/6k/40k faces;
	- Cheng Lin, Changjian Li, Yuan Liu, Nenglun Chen, Yi-King Choi, Wenping Wang. Point2Skeleton: Learning Skeletal Representations from Point Clouds. CVPR'21
		- https://github.com/clinplayer/Point2Skeleton
		- Input: point cloud, Output: skeleton
		- Skeleton: medial axis transform (MAT)
		- Model:
			- Graph initialization: topological and recovery priors;
			- GAE link prediction: graph latent by self supervision
			- Mesh generation: use GAE prediction to refine the initial graph;

## 4.1 Templates
- Legacy:
	- S. N. Sinha, D. Steedly, R. Szeliski, M. Agrawala, and M. Pollefeys. Interactive 3d architectural modeling from unordered photo collections. TOG'08
	- A.-L. Chauve, P. Labatut, and J.-P. Pons. Robust piecewise planar 3d reconstruction and completion from large-scale unstructured point data. CVPR'10
	- Sanja Fidler, Sven Dickinson, and Raquel Urtasun. 3d object detection and viewpoint estimation with a deformable 3d cuboid model. NIPS'12
	- F. Lafarge and P. Alliez. Surface reconstruction through point set structuring. CGF'13
	- A. Bodis-Szomoru, H. Riemenschneider, and L. Van Gool. Fast, approximate piecewise-planar modeling based on sparse structure-from-motion and superpixels. CVPR'14
	- Noa Fish, Melinos Averkiou, Oliver van Kaick, Olga Sorkine-Hornung, Daniel Cohen-Or, and Niloy J. Mitra. Meta-representation of shape families. TOG'14
	- Adrien Kaiser, José Alonso Ybáñez Zepeda, and Tamy Boubekeur. A survey of simple geometric primitives detection methods for captured 3d data. CGF'19
- **Morphable model** given a CAD:
	- Unclassified:
		- **Shapeflow**: Chiyu Jiang, Jingwei Huang, Andrea Tagliasacchi, and Leonidas Guibas. Shapeflow: Learnable deformations among 3D shapes. NeurIPS'20
			- https://github.com/maxjiang93/ShapeFlow
			- CNF-based;
	- Legacy:
		- 3DMM: Volker Blanz and Thomas Vetter. A morphable model for the synthesis of 3D faces. In 26th Annual Conference on Computer Graphics and Interactive Techniques'99
			- Human face;
	- Deform **each vertice**:
		- DeformNet: A Kuryenkov, J Ji, A Garg, V Mehta, J Gwak, C Choy, S Savarese. DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction from a Single Image. 2017
			- Insight: first CNN retrive a **prototype**, then CNN to deform
			- https://deformnet-site.github.io/DeformNet-website/
			- Input: single image; output: offset/deformation;
		- ALIGNet: Rana Hanocka, Noa Fish, Zhenhua Wang, Raja Giryes, Shachar Fleishman, and Daniel Cohen-Or. ALIGNet: Partial-Shape agnostic alignment via unsupervised learning. TOG'18
			- https://github.com/ranahanocka/ALIGNet
			- Input: source, **partial** target;
			- Learn a masked-autoencoder;
		- **cmr**: Angjoo Kanazawa, Shubham Tulsiani, Alexei A Efros, and Jitendra Malik. Learning category-specific mesh reconstruction from image collections. ECCV'18
		- Dominic Jack, Jhony K. Pontes, Sridha Sridharan, Clinton Fookes, Sareh Shirazi, Frederic Maire, Anders Eriksson. Learning Free-Form Deformations for 3D Object Reconstruction. ACCV'18
			- https://github.com/jackd/template_ffd
			- Input: image, some templates;
			- Learn to infer offset for each template;
		- Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan C. Russell, and Mathieu Aubry. Deep self-supervised cycle-consistent deformation for few-shot shape segmentation. Eurographics'19
			- Input: source A, target B;
			- Output: deformation;
			- Model:
				- Backbone: A, B go through pointnet, feature vA, vB;
				- Tranformation vectors: concatenate \[vA, vB\] then MLP to get p1, ..., pK;
				- Deformation: point on A go through p1, ..., pK to get final shape;
			- Supervision:
				- Chamfer distance;
				- 2-consistency: p-fAB fBA(p)
				- 3-consistency: triplet shape A, B, C, then AB, BA, CA;
		- **3DN**: Weiyue Wang, Duygu Ceylan, Radomir Mech, and Ulrich Neumann. 3dn: 3d deformation network. CVPR'19
			- https://github.com/laughtervv/3DN
			- Input: source mesh, target model (2D image/3D model);
			- Backbone:
				- Source encoder: PointNet;
				- Target encoder: CNN/PointNet for image/pc;
				- Offset Decoder: source(xyz) + source/target encoded feature -> MLP -> offset;
			- Supervision:
				- CD, EMD between deformed mesh and target;
				- Symmetry loss;
		- Eloi Mehr, Ariane Jourdan, Nicolas Thome, Matthieu Cord, and Vincent Guitteny. DiscoNet: Shapes learning on disconnected manifolds for 3d editing. ICCV'19
			- https://github.com/Fasjeit/DiscoNet
		- **DeformSyncNet**: Minhyuk Sung, Zhenyu Jiang, Panos Achlioptas, Niloy J. Mitra, and Leonidas J. Guibas. DeformSyncNet: Deformation transfer via synchronized shape deformation spaces. SIGGRAPH Asia'20
			- https://github.com/Steve-Tod/DeformSyncNet
			- Problem definition: 
				- shape editting;
				- Editting transferrable the deformation of shape pairs (a1, b1) to other pairs (a2, b2), (a3, b3)...
			- Model:
				- X x V -> Y; X: nx3 shape; v: vector representing deformation;
				- Project shape-editting to deformation space, s.t. ||Bx z - Ax v||;
				- Given source x, target y, learn dictionary model F(.) and encoder E(.) such that:
					- y = x + F(x)(E(y)-E(x))
		- **Neural cages**: Wang Yifan, Noam Aigerman, Vladimir Kim, Siddhartha Chaudhuri, and Olga Sorkine-Hornung. Neural cages for detail-preserving 3d deformations. CVPR'20
			- https://github.com/yifita/deep_cage
		- Feng Liu and Xiaoming Liu. Learning implicit functions for topology-varying dense 3d shape correspondence. NeurIPS'20
			- https://github.com/liuf1990/Implicit_Dense_Correspondence
			- Learn a latent space z s.t. enc(x)=z;
			- Learn a SEF f(.) and its inverse g(.):
				- f(p, zA) maps p to template relative space;
				- q = g(f(p, zA), zB)
	- Deform **handles**:
		- **biharmonic coordinates**: Yu Wang, Alec Jacobson, Jernej Barbic, and Ladislav Kavan. Linear subspace design for real-time shape deformation.  SIGGRAPH'15
		- **DeepMetaHandles**: Minghua Liu, Minhyuk Sung, Radomir Mech, Hao Su. DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with Biharmonic Coordinates. CVPR'21
			- https://github.com/Colin97/DeepMetaHandles
	- Deform **SDF**:
		- Feng Liu and Xiaoming Liu. Learning implicit functions for topology-varying dense 3d shape correspondence. NeurIPS'20
		- **DIT-Net**: Yu Deng, Jiaolong Yang, Xin Tong. Deformed Implicit Field: Modeling 3D Shapes with Learned Dense Correspondence. CVPR'21
			- https://github.com/microsoft/DIF-Net
	- Deform parts:
		- Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan C. Russell, and Mathieu Aubry. Deep self-supervised cycle-consistent deformation for few-shot shape segmentation. Eurographics'19
	- Articulated objects (like SMPL for Human) or **learned template/graph**:
		- Allen, B., Curless, B., Popovic, Z.: Articulated body deformation from range scan data. SIGGRAPH'02
		- Brett Allen, Brian Curless, Zoran Popovic. The space of human body shapes: reconstruction and parameterization from range scans. TOG'03
		- Dragomir Anguelov, Praveen Srinivasan,Daphne Koller, Sebastian Thrun, Jim Rodgers, and James Davis. SCAPE: shape completion and animation of people. TOG'05
		- Allen, B., Curless, B., Popovic, Z.: Learning a correlated model of identity and pose-dependent body shape variation for real-time synthesis. Symposium on Computer Animation'06
		- Silvia Zuffi and Michael J. Black. The stitched puppet: A graphical model of 3d human shape and pose. CVPR'15
		- Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael J. Black. SMPL: a skinned multi-person linear model. TOG'15
		- C. Kong, C.-H. Lin, and S. Lucey. Using locally corresponding CAD models for dense 3D reconstructions from a single image. CVPR'17
			- Task: input image, cad models of the same category, output camera pose and 3D recon;
			- Build a LDC graph;
			- Step 1: estimate a coarse camera pose and select the CAD model from the LDC graph to best register the 2D landmarks;
			- Step 2: refine the camera position and deform the best CAD model by linear combination with its neighbors in the LDC graph to fit both the landmarks and the silhouette.
		- A. Kanazawa, M. J. Black, D. W. Jacobs, and J. Malik. End-to-end recovery of human shape and pose. CVPR'18
		- **3d-coded**: Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan C. Russell, and Mathieu Aubry. 3d-coded: 3d correspondences by deep deformation. ECCV'18
			- http://imagine.enpc.fr/~groueixt/3D-CODED/
			- https://github.com/ThibaultGROUEIX/3D-CODED
		- **Chart**: Heli Ben-Hamu, Haggai Maron, Itay Kezurer, Gal Avineri, and Yaron Lipman. Multi-chart generative surface modeling. TOG'18
			- https://github.com/helibenhamu/multichart3dgans
			- Chart = Atlas?
			- Assumption: a sparse set of landmark correspondences available (6 for bones and 21 for human)
			- Basic building modules: Conformal toric charts;
				-  H. Maron, M. Galun, N. Aigerman, M. Trope, N. Dym, E. Yumer, V. G. KIM, and Y. Lipman. Convolutional neural networks on surfaces via seamless toric covers. SIGGRAPH, 2017
			- Dataset: human body and anatomical bone surfaces (teeth)
		- **Tex2shape**: Thiemo Alldieck, Gerard Pons-Moll, Christian Theobalt, and Marcus Magnor. Tex2shape: Detailed full human body geometry from a single image. ICCV'19
			- https://github.com/thmoa/tex2shape
			- SMPL + barycentric coord;
		- Keyang Zhou, Bharat Lal Bhatnagar, and Gerard Pons-Moll. Unsupervised shape and pose disentanglement for 3d meshes. ECCV'20
			- https://github.com/kzhou23/shape_pose_disent
			- SMPL-based;
			- Separate pose and shape branch;
			- Self-consistency + cross-consistency constraint;
- **Learn** a template:
	- A Kar, S Tulsiani, J Carreira, J Malik. Category-Specific Object Reconstruction from a Single Image. CVPR'15
		- https://github.com/akar43/CategoryShapes
		- Task: input some images, output camera poses and 3d model;
		- Training phase:
			- Annotated image collection (segmetnation)
			- viewpoint estimation (rotation, translation and scale): NRSfM (non-rigid) [10] from Silhouettes and keypoints
			- 3D shape from Silhouettes
			- mean-shape and deformation models: snakes/visual hull;
		- Inference phase:
			- segmentation;
			- predict viewpoint (rotation matrix) and subcategory for the object using a CNN;
			- rotate to canonical box for mean shape and deformation;
	- Zerong Zheng, Tao Yu, Qionghai Dai, Yebin Liu. Deep Implicit Templates for 3D Shape Representation. CVPR'21
		- https://github.com/ZhengZerong/DeepImplicitTemplates
		- Not just DeepSDF, deep SDF + warping;
- Retrieval:
	- Kai Xu, Hanlin Zheng, Hao Zhang, Daniel Cohen-Or, Ligang Liu, and Yueshan Xiong. Photo-inspired model-driven 3d object modeling. SIGGRAPH'11
		- Input: target image, source set of 3D models (with consistent parts labels);
		- Retrieval: manual or auto;
		- Deformation: component-wise controller (cuboid or cylinder);
			- Optimization: silhouette + symmetry;
	- Liangliang Nan, Ke Xie, and Andrei Sharf. A search-classify approach for cluttered indoor scene understanding. TOG'12
		- Deform every source and find the best fit to the target (time-consuming)
		- Problem: input 3D scan of indoor scene, output recognition and reconstruction;
		- Key-idea: a controlled region growing process which searches for meaningful objects in the scene by accumulating surface patches with high classification likelihood
		- Preprocessing: over-segment, connected graph,
		- Model: manual feature, random-forest classifier, segmentation and classification with region growing; temlate fitting with deformation;
	- Jason Rock, Tanmay Gupta, Justin Thorsen, JunYoung Gwak, Daeyun Shin, and Derek Hoiem. Completing 3d object shape from one depth image. CVPR'15
		- Non-DL, retrieve a similar mesh;
		- task: input depth map, output completed obj;
	- Yangyan Li, Hao Su, Charles Ruizhongtai Qi, Noa Fish, Daniel Cohen-Or, and Leonidas J. Guibas. Joint embeddings of shapes and images via cnn image purification. SIGGRAPH Asia'15
		- **Strong baseline** for retrieval;
	- Adriana Schulz, Ariel Shamir, Ilya Baran, David I. W. Levin, Pitchaya Sitthi-Amorn, and Wojciech Matusik. Retrieval on parametric shape collections. TOG'17
		- Parametric representation (points + tangent planes), retrieval before deforming;
		- Problem: query shape s, source parametric;
		- Traditional: fit every source and find best;
		- This paper: approximate in an embedding space;
	- C. Kong, C.-H. Lin, and S. Lucey. Using locally corresponding CAD models for dense 3D reconstructions from a single image. CVPR'17
		- Check CAD/template-based method;
	- **SceneCAD**: Armen Avetisyan, Tatiana Khanova, Christopher Choy, Denver Dash, Angela Dai, Matthias Nießner. SceneCAD: Predicting Object Alignments and Layouts in RGB-D Scans. ECCV'20
		- https://github.com/skanti/SceneCAD
		- Simultaneously predict layout and objects-cad alignment;
		- GNN;
	- Mikaela Angelina Uy, Jingwei Huang, Minhyuk Sung, Tolga Birdal, and Leonidas Guibas. Deformation-Aware 3D model embedding and retrival. ECCV'20
		- **Strong baseline** for retrieval;
		- Retrieve and optimize ARAP loss;
		- **ARAP**: Takeo Igarashi, Tomer Moscovich, and John F. Hughes. Asrigid-as-possible shape manipulation. SIGGRAPH'05
	- Yue Zhong, Yulia Gryaditskaya, Honggang Zhang, Yi-Zhe Song. Deep Sketch-Based Modeling: Tips and Tricks. 3DV'20
		- Sketch domain;
	- Mikaela Angelina Uy, Vladimir G. Kim, Minhyuk Sung, Noam Aigerman, Siddhartha Chaudhuri, Leonidas Guibas. Joint Learning of 3D Shape Retrieval and Deformation. CVPR'21
		- Insight: retrieve top K (unsupervised?), and then deform them;
		- https://joint-retrieval-deformation.github.io/
		- https://github.com/mikacuy/joint_learning_retrieval_deformation
	- Tianyu Zhao, Qiaojun Feng, Sai Jadhav, Nikolay Atanasov. CORSAIR: Convolutional Object Retrieval and Symmetry-AIded Registration. '21
		- https://acsweb.ucsd.edu/~qif007/CORSAIR/
	- Shuo Yang, Min Xu, Haozhe Xie, Stuart Perry, Jiahao Xia. Single-View 3D Object Reconstruction From Shape Priors in Memory. CVPR'21

## 4.2 Parts/Primitives
- Unclassified:
	- Siddhartha Chaudhuri, Daniel Ritchie, Jiajun Wu, Kai Xu, and Hao Zhang. Learning to generate 3D structure. Eurographics State-of-the-Art Reports (STAR), 2020.
- Legacy:
	- L. G. Roberts. Machine perception of three-dimensional solids. PhD thesis, Massachusetts Institute of Technology, 1963
	- Donald D Hoffman and Whitman A Richards. Parts of recognition. Cognition, 18(1-3):65–96, 1984
	- Alex Pentland. Parts: Structured descriptions of shape. AAAI'86
	- **geon**: I. Biederman. Recognition-by-components: a theory of human image understanding. Psychological review, 94(2):115, 1987
	- R. Schnabel, P. Degener, and R. Klein. Completion and reconstruction with primitive shapes. CGF/Eurographics'09
		- Problem: completion and reconstruction;
		- primitives as guidance, energy-based optimization;
- Ransac and fitting:
	- Attene, M., Falcidieno, B., Spagnuolo, M.: Hierarchical mesh segmentation based on fitting primitives. VC'06
	- R. Schnabel, R. Wahl, and R. Klein. Efficient ransac for point-cloud shape detection. CGF'07
	- **Fitting**: Narunas Vaskevicius and Andreas Birk. Revisiting superquadric fitting: A numerically stable formulation. PAMI'17
	- **Globfit**: Yangyan Li, Xiaokun Wu, Yiorgos Chrysanthou, Andrei Sharf, Daniel Cohen-Or, and Niloy J. Mitra. Globfit: consistently fitting primitives by discovering global relations. TOG'11
	- Adrien Kaiser, José Alonso Ybáñez Zepeda, and Tamy Boubekeur. A survey of simple geometric primitives detection methods for captured 3d data. CGF'19
		- Primitives:
			- Size, orientation, position, convex, symmetric, assembles;
			- Primitives: planes, cuboids/boxes, spheres/cylinders/cones, ellipsoids/tori/...
		- Approaches: Ransac, Hough Transform, Clustering; (region growing, ...), Assembling Primitives;
- Cosegmentation: **cross-shape consistency**;
	- A. Golovinskiy and T. Funkhouser. Learning Consistent Segmentation of 3D Models. CG'09
		- Problem: segment a set of models;
		- Energy based: a graph, similar parts **across shapes** should have consistent assignment;
	- Qi-Xing Huang, Vladlen Koltun, and Leonidas J. Guibas. oint-Shape Segmentation with Linear Programming. TOG'11
		- Unsupervised cosegmentation;
		- Stage 1: initial segment on each shape; (superpixels or clustering)
		- Stage 2: pairwise segmentation: energy-based, seg(S1)+seg(S2)+consistency(S1, S2);
		- Stage 3: multiway joint segmentation;
	- R. Hu, L. Fan, and L. Liu. Co-segmentation of 3D shapes via subspace clustering. CGF'12
	- Mehmet Ersin Yümer and Levent Burak Kara. Co-abstraction of shape collections. TOG'12
		- Problem definition: abstract (lower-res) of a set of shapes;
	- Y. Wang, S. Asafi, O. Van Kaick, H. Zhang, D. Cohen-Or, and B. Chen. Active co-analysis of a set of shapes. TOG 2012
	- Vladimir G. Kim, Wilmot Li, Niloy J. Mitra, Siddhartha Chaudhuri, Stephen DiVerdi, and Thomas A. Funkhouser. Learning part-based templates from large collections of 3d shapes. TOG'13
		- Task: given a template with gt segmentation labels, segment other shapes;
		- Jointly solving for model deformations, part segmentation, and inter-model correspondence;
		- 1. if no template provided, create auto template;
		- 2. Fit each shape with each template;
		- 3. Refine template;
	- R. Hu, O. van Kaick, B. Wu, H. Huang, A. Shamir, and H. Zhang. Learning how objects function via co-analysis of interactions. TOG 2016
	- Li Yi, Haibin Huang, Difan Liu, Evangelos Kalogerakis, Hao Su, Leonidas Guibas. Deep Part Induction from Articulated Object Pairs. SIGGRAPH Asia'18
		- https://github.com/ericyi/articulated-part-induction
	- M. Sung, H. Su, R. Yu, and L. Guibas. Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions. NeurIPS'18
		- Input n points; output: n x k dictionary; weak annotation (inconsistent/unnamed annotation);
		- Structured sparsity;
		- https://github.com/mhsung/deep-functional-dictionaries
		- Different deep dictionaries;
		- Applications with adaptation in co-segmentation, keypoint correspondence, smooth functional approximation (modeled as constraint);
		- Given an input X, At = A(X; theta) to get basis
		- Solve x = argmin||At x - f||^2 s.t. C(x)
		- Update theta = theta - eta * d L(A(X, theta); f, x) / dx
	- **BAE-Net**: Zhiqin Chen, Kangxue Yin, Matthew Fisher, Siddhartha Chaudhuri, and Hao Zhang. BAE-Net: Branched autoencoder for shape co-segmentation. CVPR'19
		- https://github.com/czq142857/BAE-NET
		- Task: unsupervised co-segmentation;
- Unsupervised part discovery:
	- Shubham Tulsiani, Hao Su, Leonidas J. Guibas, Alexei A. Efros, Jitendra Malik. Learning Shape Abstractions by Assembling Volumetric Primitives. CVPR'17
		- Supervision: unsupervised, reconstruction loss;
		- Each part (z, q, t): z, shape; q rotation; t translation;
		- REINFORCE; parsimony reward for fewer parts;
		- Experiment: ShapeNet, 32x32x32, ADAM;
	- **CSGNet**: Gopal Sharma, Rishabh Goyal, Difan Liu, Evangelos Kalogerakis, Subhransu Maji. CSGNet: Neural Shape Parser for Constructive Solid Geometry. CVPR'18
		- https://github.com/hippogriff/CSGNet
	- Yonglong Tian, Andrew Luo, Xingyuan Sun, Kevin Ellis, William T. Freeman, Joshua B. Tenenbaum, Jiajun Wu. Learning to Infer and Execute 3D Shape Programs. ICLR'19
		- http://shape2prog.csail.mit.edu/
		- https://github.com/HobbitLong/shape2prog
		- Problem setup: input voxels; output programs;
		- Program generator: Block-LSTM + step-LSTM;
		- Program executor: NPI at block-level, trained with large amount of synthetic;
		- Supervision: reconstruction;
		- Key 1: program generator needed a lot of pretrain on large synthetic (block-level LSTM); manually designed program to generate, 
		- Key 2: executor trained on part-level separately; to make generator-executor differentiable;
		- Key 3: the domain gap between the synthetic and ShapeNet is still large;
	- **Superquadrics**: Despoina Paschalidou, Ali Osman Ulusoy, and Andreas Geiger. Superquadrics revisited: Learning 3d shape parsing beyond cuboids. CVPR'19
		- https://github.com/paschalidoud/superquadric_parsing
	- **AtlasNetV2**: Theo Deprelle, Thibault Groueix, Matthew Fisher, Vladimir Kim, Bryan Russell, and Mathieu Aubry. Learning elementary structures for 3d shape generation and matching. NeurIPS'19
		- https://github.com/TheoDEPRELLE/AtlasNetV2
		- Assume all 3D data similar to a common template (also a.k.a. elemental structures);
			- Assume each shape made up of elem-struct E1, E2, ... with shape-dependent adjustment modules p1, p2, ...;
			- **if E1, E2, ... are squares or sphere: AtlasNet**
			- **if an instance shape Z as elem-struct: 3D-CODED**
		- Initial template from sampling on surface;
		- Learn to MLP-mapping or translate;
		- Supervision:
			- Correspondence error if gt deformation available and all points aligned;
			- otherwise CD;
	- **Neural Parts**: Despoina Paschalidou, Angelos Katharopoulos, Andreas Geiger, Sanja Fidler. Neural Parts: Learning Expressive 3D Shape Abstractions With Invertible Neural Networks. CVPR'21
		- https://paschalidoud.github.io/neural_parts
		- https://github.com/paschalidoud/neural_parts
		- Task: input image + 3D mesh, output a part template;
		- each part: a learned homeomorphism learned by INN;
		- Insight: part emerge without labels, temporal consistency;
	- Fenggen Yu, Zhiqin Chen, Manyi Li, Aditya Sanghi, Hooman Shayani, Ali Mahdavi-Amiri, Hao Zhang. CAPRI-Net: Learning Compact CAD Shapes with Adaptive Primitive Assembly. 2021
- Supervised:
	- Generative: given shapes with part labels, learn space to sample new shapes;
		- Charlie Nash and Chris KI Williams. The shape variational autoencoder: A deep generative model of part-segmented 3d objects. CGF'17, SGP'17
			- Task: given shapes with part labels, learn latent z;
		- Hao Wang, Nadav Schor, Ruizhen Hu, Haibin Huang, Daniel Cohen-Or, and Hui Huang. Global-to-local generative model for 3d shapes. SIGGRAPH Asia'18
		- **SDM-NET**: Lin Gao, Jie Yang, Tong Wu, Yu-Jie Yuan, Hongbo Fu, Yu-Kun Lai, and Hao(Richard) Zhang. SDM-NET: Deep generative network for structured deformable mesh. TOG'19
			- http://geometrylearning.com/sdm-net/
			- http://geometrylearning.com/sdm-net/file/sdm-code.zip
			- Two level:
				- Part level: part VAE;
				- Structure level: SP VAE; concatenate part feature in a consistent order; decode as part;
		- Rundi Wu, Yixin Zhuang, Kai Xu, Hao Zhang, and Baoquan Chen. PQ-NET: A generative part seq2seq network for 3D shapes. CVPR'20
			- https://github.com/ChrisWu1997/PQ-NET
			- Sequentially, one part at a time by GRU;
	- Compose/Assembly/Placement:
		- Siddhartha Chaudhuri, Evangelos Kalogerakis, Leonidas Guibas, and Vladlen Koltun. Probabilistic reasoning for assembly-based 3d modeling. TOG'11
			- Bayesian Network with a library of things;
		- Kalogerakis, E., Chaudhuri, S., Koller, D., Koltun, V.: A probabilistic model for component-based shape synthesis. TOG'12
		- Zheng, Y., Cohen-Or, D., Averkiou, M., Mitra, N.J.: Recurring part arrangements in shape collections. CGF'14
		- Anastasia Dubrovina, Fei Xia, Panos Achlioptas, Mira Shalah, Raphael Groscot, Leonidas Guibas. Composite Shape Modeling via Latent Space Factorization. ICCV'19
			- Input: 3D;
			- Output: editable object by manipulating semantic space;
			- Backbone:
				- Input 3D voxel -> 3D-CNN -> partition unity to 1;
				- Each part feature -> decoder -> STN -> obj;
		- **CompoNet**: Nadav Schor, Oren Katzir, Hao Zhang, and Daniel Cohen-Or. CompoNet: Learning to generate the unseen by part synthesis and composition. ICCV'19
			- https://github.com/nschor/CompoNet
			- Model:
				- Part synthesis unit: VAE for each part separately;
				- Part composition unit: compose the part;
		- Jialei Huang, Guanqi Zhan, Qingnan Fan, Kaichun Mo, Lin Shao, Baoquan Chen, Leonidas J. Guibas, Hao Dong. Generative 3D Part Assembly via Dynamic Graph Learning. NeurIPS'20
			- https://hyperplane-lab.github.io/Generative-3D-Part-Assembly/
			- https://github.com/hyperplane-lab/Generative-3D-Part-Assembly
			- Task: given part point cloud, predict assembly;
			- GNN for relation reasoning, pooling for equivalent parts (4 legs)...
	- **3d-prnn**: Chuhang Zou, Ersin Yumer, Jimei Yang, Duygu Ceylan,and Derek Hoiem. 3d-prnn: Generating shape primitives with recurrent neural networks. ICCV'17
		- https://github.com/zouchuhang/3D-PRNN
	- **SFPN**: Lingxiao Li, Minhyuk Sung, Anastasia Dubrovina, Li Yi, and Leonidas J. Guibas. Supervised fitting of geometric primitives to 3d point clouds. CVPR'19
		- Input: N x 3 point clouds; output: K (24 at maximum) primitives, (4 types: plane, cylinder, sphere, cone);
		- Key 1: membership reordering with Hungarian Matching;
		- Key 2: make RANSAC and Least-Square differentiable; separate models for each primitive;
	- **Sagnet**: Zhijie Wu, Xiang Wang, Di Lin, Dani Lischinski, Daniel Cohen-Or, and Hui Huang. Sagnet: Structure-aware generative network for 3d-shape modeling. SIGGRAPH'19
		- https://github.com/zhijieW94/SAGNet
		- Model:
			- k voxel maps;
			- K pairwise relationship;
			- GRU (RNN)
		- Training:
			- First phase: 2-way VAE for reconstruction loss;
- Hierarchical/Recursive/Graph/Scene-graph:
	- James D Foley, Foley Dan Van, Andries Van Dam, Steven K Feiner, John F Hughes, J Hughes, and Edward Angel. Computer graphics: principles and practice. 1996
	- Yanzhen Wang, Kai Xu, Jun Li, Hao Zhang, Ariel Shamir, Ligang Liu, Zhi-Quan Cheng, and Yueshan Xiong. Symmetry Hierarchy of Man-Made Objects. CGF'11
		- Symmetry hierarchy: 3D geometry is hierarchically grouped by either attachment or symmetric relationships;
	- Recursive NN:
		- **GRASS**. Jun Li, Kai Xu, Siddhartha Chaudhuri, Ersin Yumer, Hao Zhang, Leonidas Guibas. GRASS: Generative Recursive Autoencoders for Shape Structures. SIGGRAPH 2017
			- Regularity/symmetry;
			- https://github.com/kevin-kaixu/grass_pytorch
		- **Im2Struct**: Chengjie Niu, Jun Li, Kai Xu. Im2Struct: Recovering 3D Shape Structure from a Single RGB Image. CVPR'18
			- https://github.com/chengjieniu/Im2Struct
			- Recursive NN to iteratively predict primitives;
		- **SCORES**: Chenyang Zhu, Kai Xu, Siddhartha Chaudhuri, Renjiao Yi, Hao Zhang. SCORES: Shape Composition with Recursive Substructure Priors. SIGGRAPH Asia'18
			- https://github.com/BigkoalaZhu/SCORES
			- Problem setup: input two source shapes a,b, rough placement c; output optimized structure d;
		- **GRAINS**: Manyi Li, Akshay Gadi Patil, Kai Xu, Siddhartha Chaudhuri, Owais Khan, Ariel Shamir, ChangheTu, Baoquan Chen, Daniel Cohen-Or, and Hao Zhang. GRAINS: Generative recursive autoencoders for indoor scenes. TOG'19
			- https://github.com/ManyiLi12345/GRAINS
			- Tree-VAE;
	- GNN:
		- **StructureNet**: Kaichun Mo, Paul Guerrero, Li Yi, Hao Su, Peter Wonka, Niloy Mitra, Leonidas J. Guibas. StructureNet: Hierarchical Graph Networks for 3D Shape Generation. SIGGRPAH Asia'19
			- Train a graph-VAE s.t. graph -> z -> graph
			- Embed image/3d to same space as z;
		- **StructEdit**: Kaichun Mo, Paul Guerrero, Li Yi, Hao Su, Peter Wonka, Niloy J. Mitra, Leonidas Guibas. StructEdit: Learning Structural Shape Variations. 2019
			- https://github.com/daerduoCarey/structedit
			- Problem setup: 3D shape analogy; Source Si, target Sj;
			- Insight: extension of StructureNet;
		- Kai Wang, Yu-an Lin, Ben Weissmann, Manolis Savva, Angel X. Chang, and Daniel Ritchie. PlanIT: Planning and Instantiating Indoor Scenes with Relation Graph and Spatial Prior Networks. SIGGRAPH'19
			- https://github.com/brownvc/planit
			- GNN: edge defined by spatial locality of each indoor scene obj;
			- Sequential generative model: Predict one new obj at a time;
		- **DSM-Net**: Jie Yang, Kaichun Mo, Yu-Kun Lai, Leonidas J. Guibas, and Lin Gao. DSM-Net: Disentangled structured mesh net for controllable generation of fine geometry, 2020.
			- http://geometrylearning.com/dsg-net/
			- Graph-VAE;
	- Despoina Paschalidou, Luc Gool, and Andreas Geiger. Learning unsupervised hierarchical part decomposition of 3d objects from a single rgb image. CVPR'20
		- https://github.com/paschalidoud/hierarchical_primitives
		- 3 Networks:
			- Partition network: **binary** partition, each part with feature;
			- Structure network: inside/outside assignment;
			- Geometry network: superquadratics fitting;
- Applications:
	- Siddhartha Chaudhuri and Vladlen Koltun. Data-driven suggestions for creativity support in 3d modeling. ACM SIGGRAPH Asia'10
		- Given a query simple shape, suggest creativity (interactive generative model)
		- Fast match by signature;
		- Search and suggest parts with low correspondence;
	- Functionality:
		- R. Hu, W. Li, O. Van Kaick, A. Shamir, H. Zhang, and H. Huang. Learning to predict part mobility from a single static snapshot. TOG 2017
		- R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and H. Huang. Predictive and generative neural networks for object functionality. CGF 2018
	- Physics:
		- Yilun Du, Zhijian Liu, Hector Basevi, Aleš Leonardis, William T. Freeman, Joshua B. Tenenbaum, Jiajun Wu. Learning to Exploit Stability for 3D Scene Parsing. NIPS'18
- Procedural:
	- **CSG**:
		- CSG-Trees: James D Foley, Foley Dan Van, Andries Van Dam, Steven K Feiner, John F Hughes, J Hughes, and Edward Angel. Computer graphics: principles and practice. 1996
- **Chart**: Heli Ben-Hamu, Haggai Maron, Itay Kezurer, Gal Avineri, and Yaron Lipman. Multi-chart generative surface modeling. TOG'18

## 5. Implicit Functions (N-SDF)
- Legacy:
	- B. Curless and M. Levoy. A volumetric method for building complex models from range images. SIGGRAPH'96
	- **RBF**: Jonathan C. Carr, Richard K. Beatson, Jon B. Cherrie, Tim J. Mitchell, W. Richard Fright, Bruce C. McCallum, and Tim R. Evans. Reconstruction and representation of 3d objects with radial basis functions. SIGGRAPH'01
	- Greg Turk and James F. O'Brien. Modelling with implicit surfaces that interpolate. TOG'02
	- **Unity implicits**: Yutaka Ohtake, Alexander Belyaev, Marc Alexa, Greg Turk, and Hans-Peter Seidel. Multi-level partition of unity implicits, volume 22. ACM, 2003
	- Chen Shen, James F. O'Brien, and Jonathan Richard Shewchuk. Interpolating and approximating implicit surfaces from polygon soup. TOG'04
- Render for implicit models:
	- Marching Cube;
	- John C. Hart. Sphere tracing: A geometric method for the antialiased ray tracing of implicit surfaces. 1996
	- **Surface-Finding**: Sarah F. Frisken, Ronald N. Perry, Alyn P. Rockwood, and Thouis R. Jones. Adaptively sampled distance fields: A general representation of shape for computer graphics. 2000
- Generalized Neural-SDF or indicator function:
	- Union of piecewise SDF/indicator (parts?):
		- Boyang Deng, Kyle Genova, Soroosh Yazdani, Sofien Bouaziz, Geoffrey Hinton, Andrea Tagliasacchi. CvxNet: Learnable Convex Decomposition. CVPR'20
			- https://cvxnet.github.io/
			- https://github.com/tensorflow/graphics/tree/master/tensorflow_graphics/projects/cvxnet
	- Local/global:
		- **DISN**: Qiangeng Xu, Weiyue Wang, Duygu Ceylan, Radomir Mech, and Ulrich Neumann. Disn: Deep implicit surface network for high-quality single-view 3d reconstruction. 2019
			- https://github.com/laughtervv/DISN
		- Chiyu Max Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias Nießner, and Thomas A. Funkhouser. Local implicit grid representations for 3d scenes. 2020
		- Rohan Chabra, Jan Eric Lenssen, Eddy Ilg, Tanner Schmidt, Julian Straub, Steven Lovegrove, and Richard Newcombe. Deep local shapes: Learning local SDF priors for detailed 3d reconstruction. CoRR'20
		- PatchNets: Edgar Tretschk, Ayush Tewari, Vladislav Golyanik, Michael Zollhöfer, Carsten Stoll, and Christian Theobalt. PatchNets: Patch-Based Generalizable Deep Implicit 3D Shape Representations. ECCV'20
			- https://github.com/edgar-tr/patchnets
		- Moritz Ibing, Isaak Lim, Leif Kobbelt. 3D Shape Generation With Grid-Based Implicit Functions. CVPR'21
	- **OccNet**: Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas Geiger. Occupancy networks: Learning 3d reconstruction in function space. CVPR'19
		- Insight: new 3D representation, could generate mesh at any resolution;
		- https://github.com/autonomousvision/occupancy_networks
		- Input image; output: **continuous decision boundary of a deep-NN**;
		- Learn an occupancy function: R3 to [0,1];
		- Surface at inference time: Multiresolution IsoSurface Extraction (MISE) or Marching Cube;
	- **IM-Net**: Zhiqin Chen and Hao Zhang. Learning implicit fields for generative shape modeling. CVPR'19
		- https://github.com/czq142857/implicit-decoder
	- **DeepSDF**: Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven Lovegrove. DeepSDF: Learning continuous signed distance functions for shape representation. CVPR'19
		- Insight: point-based SDF;
		- https://github.com/facebookresearch/DeepSDF
		- Formulation: given a point x, a NN with latent code z as a classifier \
			<img src="/CV-3D/images/3d_output/deepsdf-1.png" alt="drawing" width="350"/>
		- Autoencoder: \
			<img src="/CV-3D/images/3d_output/deepsdf-2.png" alt="drawing" width="400"/>
		- Auto-decoder (encoder-less) training and inference: \
			<img src="/CV-3D/images/3d_output/deepsdf-3.png" alt="drawing" width="400"/>
			<img src="/CV-3D/images/3d_output/deepsdf-4.png" alt="drawing" width="400"/>
	- **SIF**: Kyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna, William T Freeman, and Thomas Funkhouser. Learning shape templates with structured implicit functions. ICCV'19
		- https://github.com/google/ldif
		- Union of scaled axis-aligned anisotropic 3D Gaussians;
	- **DSIF**: Kyle Genova, Forrester Cole, Avneesh Sud, Aaron Sarna, and Thomas A. Funkhouser. Deep structured implicit functions. CoRR, abs/1912.06126, 2019
	- **Pifu**: Shunsuke Saito, Zeng Huang, Ryota Natsume, Shigeo Morishima, Angjoo Kanazawa, and Hao Li. Pifu: Pixel-aligned implicit function for high-resolution clothed human digitization. ICCV'19
		- https://shunsukesaito.github.io/PIFu/
		- Learn inside/outside, then marching cube;
	- Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, and Yaron Lipman. Implicit geometric regularization for learning shapes. ICML'20
		- Add a regularization:
			- encourages f() to vanish on X and
			- if normal data exists (i.e., τ = 1), that df/dx is close to the supplied normals N
	- **PIFuHD**: Shunsuke Saito, Tomas Simon, Jason Saragih, and Hanbyul Joo. PIFuHD: Multi-level pixel-aligned implicit function for high-resolution 3D human digitization. CVPR'20
	- **SAL**: Matan Atzmon and Yaron Lipman. SAL: Sign agnostic learning of shapes from raw data. CVPR'20
	- Saurabh Singh, Danhang Danny Tang, Phil Chou, Christian Haene, Mingsong Dou, Sean Fanello, Jonathan Taylor, Onur Gonen Guleryuz, Yinda Zhang, Shahram Izadi, Andrea Tagliasacchi, Sofien Bouaziz, and Cem Keskin. Deep implicit volume compression. CVPR'20
	- SAL++: Matan Atzmon and Yaron Lipman. SAL++: Sign agnostic learning with derivatives. arxiv'20
	- **BSPNet**: Zhiqin Chen, Andrea Tagliasacchi, and Hao Zhang. BSPNet: Generating compact meshes via binary space partitioning. CVPR'20
	- **Dualsdf**: Zekun Hao, Hadar Averbuch-Elor, Noah Snavely, and Serge Belongie. Dualsdf: Semantic shape manipulation using a two-level representation. arXiv, 2020.
	- Michael Niemeyer, Lars Mescheder, Michael Oechsle, and Andreas Geiger. Differentiable volumetric rendering: Learning implicit 3D representations without 3D supervision. CVPR'20
		- https://github.com/autonomousvision/differentiable_volumetric_rendering
		- Learn implicit function from 2D supervision;
	- Yueqi Duan, Haidong Zhu, He Wang, Li Yi, Ram Nevatia, and Leonidas J. Guibas. Curriculum deepsdf, 2020
		- https://github.com/haidongz-usc/Curriculum-DeepSDF
		- Built on DeepSDF, train with progressive difficulty (error tolenrance)
	- Vincent Sitzmann, Julien NP Martel, Alexander W Bergman, David B Lindell, and Gordon Wetzstein. Implicit neural representations with periodic activation functions. NeurIPS'20
		- https://vsitzmann.github.io/siren/
	- Thomas Davies, Derek Nowrouzezahrai, and Alec Jacobson. On the effectiveness of weight-encoded neural implicit 3D shapes. ICML'21
		- https://github.com/u2ni/ICML2021
		- Neural SDF fitting;
- Matching, N-SDF across frames/shapes;
	- Michael Niemeyer, Lars M. Mescheder, Michael Oechsle, and Andreas Geiger. Occupancy flow: 4d reconstruction by learning particle dynamics. ICCV'19
		- CNF;
	- Feng Liu and Xiaoming Liu. Learning implicit functions for topology-varying dense 3d shape correspondence. NeurIPS'20
- 3D-Field:
	- **SRN**: Vincent Sitzmann, Michael Zollhofer, and Gordon Wetzstein. Scene representation networks: Continuous 3d-structure-aware neural scene representations. NeurIPS'19
		- https://github.com/vsitzmann/scene-representation-networks
	- **NERF**: Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. NeRF: Representing scenes as neural radiance fields for view synthesis. ECCV'20
		- Insight: overfit a function mlp(x,y,z,theta,phi) to explain the scene;
		- Key techniques to improve novel view synthesis performance:
			- Positional encoding;
			- Multi-resolution;
- Sampling technique:
	- Wang Yifan, Shihao Wu, Cengiz Öztireli, Olga Sorkine-Hornung. Iso-Points: Optimizing Neural Implicit Surfaces With Hybrid Representations. CVPR'21
- Matthew Tancik, Pratul P. Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan T. Barron, and Ren Ng. Fourier features let networks learn high frequency functions in low dimensional domains. NeurIPS'20

## 2.5D, Depth, Skeleton, 3D-Aware 2D Cues...
- Depth:
	- Wei Yin, Yifan Liu, Chunhua Shen, and Youliang Yan. Enforcing geometric constraints of virtual normal for depth prediction. ICCV'19
- S. Galliani and K. Schindler. Just look at the image: Viewpoint-specific surface normal prediction for improved multi-view reconstruction. CVPR'16
	- Estimate **normal** of depth map; then improve depth map fusion;
- **3D-INN**: J Wu, T Xue, J Lim, Y Tian, J Tenenbaum, A Torralba, and W Freeman. Single Image 3D Interpreter Network, ECCV'16, IJCV'18
	- Key insight: skeleton representation for 3D objects (so keypoints infers 3D);
	- Input: single image; output: 2d keypoints as well as 3d structure;
	- Keypoint detection (CNN) -> keypoint refinement (mini-network like auto-encoder) -> 3D interpreter -> Projection Layer;\
	<img src="/CV-3D/images/3d_output/3d-inn.png" alt="drawing" width="600"/>
- **MarrNet**: J Wu, Y Wang, T Xue, X Sun, W Freeman, and J Tenenbaum. MarrNet: 3D Shape Reconstruction via 2.5D Sketches. NIPS'17
	- Key insight: 3D-cues first (2.5-D: normal, depth, silhouette), then 3D shape
	- http://marrnet.csail.mit.edu/
	- https://github.com/jiajunwu/marrnet
	- Input: image; output: voxel;
	- Network: encoder (ResNet-18) - decoder (input normal image + depth image masked by silhouette);
	- Supervision: (2D-3D Reprojection consistency)
		- Depth map with voxel: L2;
		- Surface normal; (surface orthogonal to normal should be 1)
	<img src="/CV-3D/images/3d_output/marrnet.png" alt="drawing" width="600"/>
- Wilfried Hartmann, Silvano Galliani, Michal Havlena, Luc Van Gool, and Konrad Schindler. Learned multi-patch similarity. ICCV'17
- **DeepMVS**: P Huang, K Matzen, J Kopf, N Ahuja, and J Huang. DeepMVS: Learning Multi-view Stereopsis. CVPR'18
- **ShapeHD**: J. Wu, C. Zhang, X. Zhang, Z. Zhang, W. T. Freeman, and J. B. Tenenbaum. Learning shape priors for single-view 3D completion and reconstruction. ECCV'18
	- Key insigth: improve on MarrNet with naturalness (pretrained discriminator) to solve ambiguity, with Wasserstein-GAN loss;
	- https://github.com/xiumingzhang/GenRe-ShapeHD
	- Input: single view; Output: 3D voxel completion/reconstruction; \
	<img src="/CV-3D/images/3d_output/shapehd.png" alt="drawing" width="600"/>
- Simon Donne and Andreas Geiger. Learningnon-volumetric depth fusion using successive reprojections. CVPR'19