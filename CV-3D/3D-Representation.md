# 3D Data as Output (Objects)

## Basics
- Representations:
	- Point clouds;
	- Voxel;
	- Mesh;
	- Oct-tree;
	- Templates: Primitives; Implicit functions;
	- Depth; 2.5D;
	- Important task: fusion; (KinectFusion, ...)
- Supervision and Evaluation:
	- Geometry:
		- **Chamfer distance**: H. G. Barrow, J. M. Tenenbaum, R. C. Bolles, and H. C. Wolf. Parametric Correspondence and Chamfer Matching: Two New Techniques for Image Matching. IJCAI'77
			- Sum of closest point distances
			- Asymmetric
			- For Hausdorff distance, simply a distance transform?
		- EMD;
	- Photometric;
- 3D reconstruction:
	- Direct 3D reconstruction for whole object;
	- Scene: depth map;
	- Infer cues:
		- 2.5-D: - H. G. Barrow and J. M. Tenenbaum, Recovering intrinsic scene characteristics from images, Computer Vision Systems, 1978

## 1. Point Cloud
- Basics:
	- Directly map from latent space z to nx3 dim as n points; (most AE)
	- Fold a 2D surface/rectangle (folding net)
	- Deform a Gaussian ball (CNF, pointflow)
- **PSGN**: H Fan, H Su, and L Guibas. A point set generation network for 3d object reconstruction from a single image. CVPR'17
	- Key insight: hourglass better; random variable;
	- https://github.com/fanhqme/PointSetGeneration
	- Input: image, random variable r; output: point cloud;
	- Net-structure: encoder, predictor;
	- Supervision: 1. Chamfer distance; 2. EMD with approximation;
	<img src="/CV-3D/images/3d_output/point-set-gen.png" alt="drawing" width="600"/>
- Nobuyuki Umetani. Exploring Generative 3D Shapes Using Autoencoder Networks. SIGGRAPH Asia'17
	- AutoEncoder on 3D points and hand-coded features;
- **AAE**: Maciej Zamorski, Maciej Zieba, Rafał Nowak, Wojciech Stokowiec, and Tomasz Trzciński. Adversarial autoencoders for generating 3d point clouds. 2018
	- Build on Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. Adversarial autoencoders. 2015
- Chen-Hsuan Lin, Chen Kong, and Simon Lucey. Learning efficient point cloud generation for dense 3d object reconstruction. AAAI'18
- Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas Guibas. Learning representations and generative models for 3d point clouds. ICML'18
	- Input/output: point cloud;
	- AE, x -> z=f(x) -> x'
	- Supervision: Chamfer(x, x')
- **FoldingNet**: Y. Yang, C. Feng, Y. Shen, and D. Tian. Foldingnet: Interpretable unsupervised learning on 3d point clouds. CVPR'18
	- https://www.merl.com/research/license#FoldingNet
	- AE
	- Encoder: MLP + graph-based matrix pooling; output a 512 x 1 dim feature;
		- Graph: K-NN graph, 3 (xyz) + 9 (covariance) = 12-dimension; (local pooling like PointNet++)
	- Decoder: takes 512-dim feature and fixed 2D grid, fold; m x 514-dim input; 512d + xy;
		- MLP;
- Matheus Gadelha, Rui Wang, and Subhransu Maji. Multiresolution tree networks for 3d point cloud processing. ECCV'18
	- VAE
- Chun-Liang Li, Manzil Zaheer, Yang Zhang, Barnabas Poczos, and Ruslan Salakhutdinov. Point cloud gan. ICLR'19
	- Theoretical paper: derive WGAN-style divergence for point set;
	- Experiment: built on AE
- Diego Valsesia, Giulia Fracastoro, and Enrico Magli. Learning localized generative models for 3d point clouds via graph convolution. ICLR'19
- Ruihui Li, Xianzhi Li, Chi-Wing Fu, Daniel Cohen-Or, and Pheng-Ann Heng. PU-GAN: A point cloud upsampling adversarial network. ICCV'19
- **CNF**:
	- **Pointflow**: Guandao Yang, Xun Huang, Zekun Hao, Ming-Yu Liu, Serge Belongie, and Bharath Hariharan. Pointflow: 3d point cloud generation with continuous normalizing flows. ICCV'19
		- CNF based model;
	- Shitong Luo, Wei Hu. Diffusion Probabilistic Models for 3D Point Cloud Generation. CVPR'21
		- https://github.com/luost26/diffusion-point-cloud
		- MCMC
- Dong Wook Shu, Sung Woo Park, and Junseok Kwon. 3d point cloud generative adversarial network based on tree structured graph convolutions. ICCV'19

## 2. Voxel
- Basics:
	- Input: 3D (AE), image (reconstruction), partial (inpainting), ... encoder to z;
	- Then z back to complete shape;
	- With camera parameter: unproject/ray tracing in 3D-Conv;
	- Supervision:
		- Strong: Direct 3D occupancy;
		- Weak: Indirect 2D rendering consistency, or Inverse Graphics;
	- Handle multiple inputs:
		- Carving to satisfy multiple constraint;
		- CNN-RNN (problem: not order-invariant);
		- Fusion network;
- Legacy (Non-DL):
	- **Voxlet**: Michael Firman, Oisin Mac Aodha, Simon Julier, Gabriel J. Brostow. Structured Prediction of Unobserved Voxels From a Single Depth Image. CVPR'16
		- https://github.com/mdfirman/voxlets
		- Input depth image (no-rgbd), output voxel binary occupancy;
		- Model: structured random forest;
- 3D-Deconv from latent space:
	- Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3d shapenets: A deep representation for volumetric shapes. CVPR'15
		- Input: image; output: voxel;
	- **3D-R2N2**: Christopher B. Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, Silvio Savarese. 3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction. ECCV'16
		- https://github.com/chrischoy/3D-R2N2
		- Input: single/multiple images; output: voxel;
		- Model:
			- CNN-RNN: CNN (ResNet), RNN to update model with RNN each time with a new image;
			- RNN: no output gates, only output at final;
		- Supervision: binary cross-entropy on the final output;
		<img src="/CV-3D/images/3d_output/3d-r2n2.png" alt="drawing" width="500"/>
	- R Girdhar, D F Fouhey, M Rodriguez, and A Gupta. Learning a predictable and generative vector representation for objects. ECCV'16
		- Problem definition: AE
		- Input: Voxel, image; Output: voxel;
		- Model:
			- Encoder: concatenate of features conv3d for voxel, conv2d for image;
			- Decoder: 3D-deconv;
	- Danilo Jimenez Rezende, SM Eslami, Shakir Mohamed, Peter Battaglia, Max Jaderberg, and Nicolas Heess. Unsupervised learning of 3d structure from images. NIPS'16
		- Key insight: **c-VAE** style;
		- Input: single image/voxel;
		- Supervision: 2D-weak-sup; REINFORCE to bypass back-prop through black-box renderer;
		- Experiment: ShapeNet;
		<img src="/CV-3D/images/3d_output/unsup-3d.png" alt="drawing" width="600"/>
	- Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum. Learning a probabilistic latent space of object shapes via 3d generative adversarial modeling. NIPS'16
		- GAN / GAN-VAE;
		- Noisy / Blurry;
	- Andrew Brock, Theodore Lim, James M Ritchie, and Nick Weston. Generative and discriminative voxel modeling with convolutional neural networks. 3D Deep Learning Workshop at NIPS'16
		- VAE;
		- https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling
	- **HSP**: C Hane, S Tulsiani, J Malik. Hierarchical Surface Prediction for 3D Object Reconstruction. 3DV'17
		- Insight: **coarse to fine**, 16^3 to 32^3 to ... 256^3; only nodes on boundary needs upsamplng;
		- https://github.com/chaene/hsp
		- Input: color, depth, partial volume; Ouptut: voxel (3 classes: free, **boundary**, occupied)
		- CNN with deep-supervision on different resolution
		- Most important part: predict layer l+1 based on layer l (e.g. from 16^3 to 32^3)
			- 1. Feature Cropping: (b/2+2p)^3 region with p padding;
			- 2. Upsampling: (b+2p)^3 region
			- 3. Output generation: max boundary prediction reponse; above threshold, expand child;
		<img src="/CV-3D/images/3d_output/factor3d.png" alt="drawing" width="600"/>
	- **PrGAN**: Matheus Gadelha, Subhransu Maji and Rui Wang. 3D Shape Induction from 2D Views of Multiple Objects. 3DV'17
		- https://github.com/matheusgadelha/PrGAN
		- Input: latent code 200-dim;
		- Backbone: 3d-deconv;
		- Supervision: weak-supervised, project to 2D then a discriminator;
	- D. Stutz and A. Geiger. Learning 3D shape completion from laser scan data with weak supervision. CVPR'18
		- Problem: 3D completion;
		- Model:
			- Step 1: VAE y -> y'
			- Step 2: keep the decoder, train an encoder to map partial data to the same latent space;
	- Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or, and H. Huang. SAGNet: Structure-aware generative network for 3d-shape modeling. TOG'19
		- GRU + VAE;
- **Unproject** from 2D (assume known camera pose?):
	- A. O. Ulusoy, A. Geiger, and M. J. Black. Towards probabilistic volumetric reconstruction using ray potentials. 3DV'15
	- **PTN**: X Yan, J Yang, E Yumer, Y Guo, and H Lee. Perspective transformer nets: Learning single-view 3d object reconstruction without 3d supervision. NIPS'16
		- Insight: encoder-decoder for 2d-3d, no 3d supervision, silhouette supervision from different views instead of gt;
		- https://github.com/xcyan/ptnbhwd
		- Input: image; output: voxel;
		- Assumption: clean background;
		- Encoder-decoder: view-invariant encoder for image h(I), decoder generates 3d v=g(h(I));
		- Supervision: silhouette-based volumetric loss from space carving;
		<img src="/CV-3D/images/3d_output/per-trans-net.png" alt="drawing" width="600"/>
	- J. Gwak, C. B. Choy, M. Chandraker, A. Garg, and S. Savarese. Weakly supervised 3d reconstruction with adversarial constraint. 3DV'17
		- Input: multiple images;
		- Backbone: CNN-RNN;
		- Final output ray-trace pooling to get 2D projection;
		- Supervision: adversarial with 3d shapes;
	- **Surfacenet**: Ji, M., Gall, J., Zheng, H., Liu, Y., Fang, L. Surfacenet: An end-to-end 3d neural network for multiview stereopsis. ICCV'17
		- Insight: end-to-end multi-view stereo; geometry with color encoded in voxel with **unproject**;
		- https://github.com/mjiUST/SurfaceNet
		- Input: images with camera pose; Output: 3D voxel, with [0,1] for on surface or not;
		- Turn images to CVC (color voxel cube)\
		<img src="/CV-3D/images/3d_output/surface-net1.png" alt="drawing" width="350"/>
		<img src="/CV-3D/images/3d_output/surface-net2.png" alt="drawing" width="350"/>
	- **LSM**: A. Kar, C. Häne, J. Malik. Learning a multi-view stereo machine. NIPS'17
		- https://github.com/akar43/lsm
		- Input: multiple images; Output: 32^3 Voxel 3D;
		- Assumption: **camera pose known**;
		- Cost volume; \
		<img src="/CV-3D/images/stereo/lsm1.png" alt="drawing" width="500"/>
		<img src="/CV-3D/images/stereo/lsm2.png" alt="drawing" width="500"/>
	- **MVC**: S Tulsiani, A Efros, J Malik. Multi-view Consistency as Supervisory Signal for Learning Shape and Pose Prediction. CVPR'18
		- Key insight: **unknown-shape**, 
		- https://github.com/shubhtuls/mvcSnP
		- Input: single image; output: camera pose, 3D-shape;
		- Training mode: (two images of an object as input)
			- Shape from first view; (conanical view?)
			- Pose from second view;
		- Test mode: independent shape and pose;
		<img src="/CV-3D/images/3d_output/mvc.png" alt="drawing" width="600"/>
	- Stephan R. Richter and Stefan Roth. Matryoshka networks: Predicting 3d geometry via nested shape layers. CVPR'18
		- Input: image, camera pose;
		- Voxel tube: input 2D feat nt x nt x f, finally get 3D no x no x no;
		- Shape layer: efficiently compress voxel tubes: record enter and exit shape;
		- Nested shape layers: similar to CSG? (handle image input one by one like Matryoshka doll)
	- **DRC**: S Tulsiani, T Zhou, A Efros, J Malik. Multi-view Supervision for Single-view Reconstruction via Differentiable Ray Consistency.  PAMI'19
		- Key insight: relax 3D GT requirement to 2D consistency!
		- https://github.com/shubhtuls/drc (torch);
		- Input: image (model) + multiple images (refine?); Output: voxel for 3d;
		- Model: ray termination event;	Event: a ray intersect a voxel, previous voxels are all unoccupied
		- Supervision:
			- Depth, Foreground mask
			- Per-ray consistency loss
		- Experiment: ShapeNet; PASCAL 3D
		<img src="/CV-3D/images/3d_output/drc.png" alt="drawing" width="600"/>
	- Edward Smith, Scott Fujimoto, David Meger. Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation. NIPS'18
		- https://github.com/EdwardSmith1884/Multi-View-Silhouette-and-Depth-Decomposition-for-High-Resolution-3D-Object-Representation
		- Main insight: high-resolution (512 x 512 x 512);
		- Input: 2D image or 3D low-res voxel;
		- Model:
			- Representation: six axis-aligned orthographic depth maps (ODM);
				- Super-resolve the ODM;
			- 3D model carving: use high-res ODM to update 3D-voxel;
	- **SATNet**: Shice Liu, YU HU, Yiming Zeng, Qiankun Tang, Beibei Jin, Yinhe Han, Xiaowei Li. See and Think: Disentangling Semantic Scene Completion. NIPS'18
		- https://github.com/ShiceLiu/SATNet
		- Input: 2D image/depth map;
		- Model: 3 components;
			- SNet: 2D Semantic Segmentation
			- 2D-3D Reprojection Layer: given depth, sem label, intrinsic, extrinsic, unproject to get voxel as D x Sx x Sy x Sz;
			- TNet: 3D Semantic Scene Completion;
	- Haozhe Xie, Hongxun Yao, Xiaoshuai Sun, Shangchen Zhou, and Shengping Zhang. Pix2vox: Context-aware 3d reconstruction from single and multi-view images. ICCV'19
		- https://infinitescript.com/project/pix2vox/
		- Insight: Fusion of different 3D voxel with **context-aware-fusion network**;
			- Select confident (seen) parts from each image;
		- Refiner net to super-resolve;
- Oct-Tree:
	- **OGN**: Maxim Tatarchenko, Alexey Dosovitskiy, and Thomas Brox. Octree generating networks: Efficient convolutional architectures for high-resolution 3d outputs. ICCV'17
		- Key: **Coarse to fine**;
		- https://github.com/lmb-freiburg/ogn
		- Input: image; output: voxel;
		<img src="/CV-3D/images/3d_output/ogn.png" alt="drawing" width="600"/>
	- Gernot Riegler, Ali Osman Ulusoy, Horst Bischof, and Andreas Geiger. Octnetfusion: Learning depth fusion from data. 3DV'17
	- **Adaptive O-CNN**: Peng-Shuai Wang, Chun-Yu Sun, Yang Liu, and Xin Tong. Adaptive O-CNN: a patch-based deep representation of 3d shapes. SIGGRAPH Asia'18
- From other info:
	- **GenRe**: X Zhang, Z Zhang, C Zhang, J Tenenbaum, W Freeman and J Wu. Learning to Reconstruct Shapes from Unseen Classes. NIPS'18
		- Insight: project to spherical map;
		- Input: single image;
		- https://github.com/xiumingzhang/GenRe-ShapeHD
		<img src="/CV-3D/images/3d_output/genre.png" alt="drawing" width="600"/>

## 3. Mesh
- Legacy:
	- Voronoi diagram;
	- Delaunay triangulation;
- Legacy: Marching Cubes;
	- Given function defining +/- as outside inside, output the surface (mesh);
	- Insight: go through each cube independently, lookup table (2 ^ 8 = 256 cases), handle the surface accordingly by lookup, adapt to find a better surface;
	- http://www.cs.carleton.edu/cs_comps/0405/shape/marching_cubes.html
	- **Marching cubes**: W. E. Lorensen and H. E. Cline. Marching cubes: A high resolution 3d surface construction algorithm. SIGGRAPH'87
		- Input: mask; output: mesh triangulation;
	- https://www.boristhebrave.com/2018/04/15/marching-cubes-tutorial/
	- https://www.boristhebrave.com/2018/04/15/marching-cubes-3d-tutorial/
	- https://github.com/BorisTheBrave/mc-dc
- Legacy: **Poisson Surface Reconstruction**
	- Input: given **discrete** points with known **oriented normals**, construct continuous watertight surface with **implicit function** that best match the normal;
		- Image the function is defined on the 3D space as
			- f(x) = 0 outside
			- f(x) = 1 inside;
			- grad(f(x)) oriented normals on surface;
			- Goal: get f(x) everywhere;
			- Smoothing (convolve with Gaussian kernel);
			- grad(f(x)) = smoothed (normal)
			- Min square solution: Laplacian(f(x)) = grad (normal)
			- To get f(x): marching cube on the oct-tree;
	- M. M. Kazhdan, M. Bolitho, and H. Hoppe. Poisson surface reconstruction. SGP'06
	- M. M. Kazhdan and H. Hoppe. Screened poisson surface reconstruction. SIGGRAPH'13
- Legacy: deform an initial mesh;
	- Similar to active-contour, leads to local minima;
	- Andrei Sharf, Thomas Lewiner, Ariel Shamir, Leif Kobbelt, and Daniel Cohen-Or. 2006. Competing fronts for coarse–to–fine surface reconstruction. CGF'06
- Legacy:
	- Hugues Hoppe. Progressive meshes. SIGGRAPH'96
	- F. Bernardini, J. Mittleman, H. Rushmeier, C. Silva, and G. Taubin. The ball-pivoting algorithm for surface reconstruction. TVCG'99
	- F. Calakli and G. Taubin. SSD: smooth signed distance surface reconstruction. CGF'11
- Direct mesh by downsample, upsample:
	- **Coma**: A. Ranjan, T. Bolkart, S. Sanyal, and M. J. Black. Generating 3D faces using convolutional mesh autoencoders. ECCV'18
		- https://coma.is.tue.mpg.de/
	- **MeshCNN**: Rana Hanocka, Amir Hertz, Noa Fish, Raja Giryes, Shachar Fleishman, Daniel Cohen-Or. MeshCNN: A Network with an Edge. SIGGRAPH'19
		- https://ranahanocka.github.io/MeshCNN/
		- https://github.com/ranahanocka/MeshCNN/
		- https://docs.google.com/presentation/d/1yLZ6uyAujyF0MtFWofAMFgWQpWaDYqS8vkdge_lzk6g/edit#slide=id.g35f391192_00
		- Insight: edges + affinity from meshes;
		- Mesh-Conv:\
			<img src="/CV-3D/images/3d_output/mesh-conv.png" alt="drawing" width="400"/>
		- Mesh-Pool: remove edges to collapse (5 edges -> 2)\
			<img src="/CV-3D/images/3d_output/mesh-pool-1.png" alt="drawing" width="400"/>
			<img src="/CV-3D/images/3d_output/mesh-pool-2.png" alt="drawing" width="400"/>
		- Mesh-Unpool:\
			<img src="/CV-3D/images/3d_output/mesh-unpool.png" alt="drawing" width="400"/>
- Deformation-based:
	- DeformNet: A Kuryenkov, J Ji, A Garg, V Mehta, J Gwak, C Choy, S Savarese. DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction from a Single Image. 2017
		- Check CAD/template-based method;
	- Q Tan, L Gao, Y Lai, J Yang and S Xia. Mesh-based Autoencoders for Localized Deformation Component Analysis. 2017
		- AutoEncoder;
		- Input: multiple mesh; output: new mesh synthesis (deformation);
		- Point feature: manually designed;
		- Encoder: GCN;
		- Decoder: mirrored encoder?
	- **cmr**: Angjoo Kanazawa, Shubham Tulsiani, Alexei A Efros, and Jitendra Malik. Learning category-specific mesh reconstruction from image collections. ECCV'18
		- https://github.com/akanazawa/cmr
		- Input: image; Output mesh;
		- Model:
			- Encoder: image -> 2D-CNN to get latent feature shared by three output modules;
			- Output: 1. camera pose; 2. deformation; 3. texture;
		- Supervision: mask + keypoitn + texture;
		<img src="/CV-3D/images/3d_output/cmr.png" alt="drawing" width="550"/>
	- **Pixel2mesh**: Nanyang Wang, Yinda Zhang, Zhuwen Li, Yanwei Fu, Wei Liu, and Yu-Gang Jiang. Pixel2mesh: Generating 3d mesh models from single rgb images. ECCV'18
		- GCN to deform a ball; unpool to add more nodes and edges;
		- CD for supervision;
		- https://github.com/nywang16/Pixel2Mesh
		<img src="/CV-3D/images/3d_output/pixel2mesh-1.png" alt="drawing" width="500"/>
		<img src="/CV-3D/images/3d_output/pixel2mesh-2.png" alt="drawing" width="500"/>
	- **Geometrics**: Edward J Smith, Scott Fujimoto, Adriana Romero, and David Meger. Geometrics: Exploiting geometric structure for graph-encoded objects. ICML'19
		- https://github.com/EdwardSmith1884/GEOMetrics
	- **Pixel2mesh++**: Chao Wen, Yinda Zhang, Zhuwen Li, and Yanwei Fu. Pixel2mesh++: Multi-view 3d mesh generation via deformation. ICCV'19
		- https://github.com/walsvid/Pixel2MeshPlusPlus
		- Extension of Pixel2mesh;
		- First Pixel2mesh to get a coarse mesh;
		- Then iterative module to refine by multi-view with GCN;
	- **Mesh R-CNN**: Georgia Gkioxari, Jitendra Malik, and Justin Johnson. Mesh R-CNN. ICCV'19
		- https://gkioxari.github.io/meshrcnn/
		- https://github.com/facebookresearch/meshrcnn
		- Problem setup: input single image, output a set of detected object instances, with a triangle mesh for each object.
		- Approach: Mask R-CNN, coarse voxel (initial mesh), mesh refinement;
			<img src="/CV-3D/images/3d_output/mesh-rcnn.png" alt="drawing" width="600"/>
		- Lift to 3D: w x h G-channel;
		- Cubify: voxel to triangular mesh (8 vertices, 18 edges, 12 faces); merge shared edges and vertices; eliminate interior ones;
		- Mesh refinement (similar to **Pixel2mesh**):
			- 1. vertex alignment, which extracts image features for vertices; (with camera intrinsic)
			- 2. graph convolution, which propagates information along mesh edges;
			- 3. vertex refinement， which updates vertex positions.
		- Supevision: similar to **Geometrics**; sample points, Chamfer-Distance;
	- Charlie Nash, Yaroslav Ganin, S. M. Ali Eslami, and Peter W. Battaglia. PolyGen: An autoregressive generative model of 3d meshes. ICML'19
		- https://github.com/deepmind/deepmind-research/tree/master/polygen
		- **Transformer** on points and faces;
- Retrieval:
	- C. Kong, C.-H. Lin, and S. Lucey. Using locally corresponding CAD models for dense 3D reconstructions from a single image. CVPR'17
		- Check CAD/template-based method;
- Mesh from other representations (with differentiable op):
	- Y. Liao, S. Donne, and A. Geiger. Deep marching cubes: Learning explicit surface representations. CVPR'18
		- Differentiable Marching Cubes;
- Piecewise surface:
	- **AtlasNet**. T. Groueix, M. Fisher, V. G. Kim, B. C. Russell, and M. Aubry. Atlasnet: A papier-mache approach to learning 3d surface generation. CVPR'18
		- https://github.com/ThibaultGROUEIX/AtlasNet
		- Input point cloud or image encoded by a NN as feature f(x)
		- Then, f(x) and points sampled on a rectangle reconstruct an atlas on shape x;
			- Multiple MLP for multiple patches (Atlas);
- Mesh from point cloud;
	- **DGP**: Francis Williams, Teseo Schneider, Claudio Silva, Denis Zorin, Joan Bruna, and Daniele Panozzo. Deep geometric prior for surface reconstruction. CVPR'19
		- Similar to deep-image-prior;
	- Rana Hanocka, Gal Metzer, Raja Giryes, Daniel Cohen-Or. Point2Mesh: A Neural Self-Prior for Deformable Meshes. SIGGRAPH'20
		- Insight: coarse-to-fine MeshCNN:
			<img src="/CV-3D/images/3d_output/point2mesh.png" alt="drawing" width="500"/>
		- Loss: Mesh to Point Cloud Distance: Chamfer + differentiable sampler;
		- Loss: Beam-gap loss: to handle narrow deep cavity;
		- Implementation: iterative for K=1000 iterations by network, then pass to RWM [Huang'18] to generate manifold, watertight and non-interscting surface;
		- Runtime (per iteration): 0.23/0.59/4.7 sec on 2k/6k/40k faces;
	- Cheng Lin, Changjian Li, Yuan Liu, Nenglun Chen, Yi-King Choi, Wenping Wang. Point2Skeleton: Learning Skeletal Representations from Point Clouds. CVPR'21
		- https://github.com/clinplayer/Point2Skeleton
		- Input: point cloud, Output: skeleton
		- Skeleton: medial axis transform (MAT)
		- Model:
			- Graph initialization: topological and recovery priors;
			- GAE link prediction: graph latent by self supervision
			- Mesh generation: use GAE prediction to refine the initial graph;

## 4. Templates/Primitives (Also check composition folder)
- Legacy:
	- S. N. Sinha, D. Steedly, R. Szeliski, M. Agrawala, and M. Pollefeys. Interactive 3d architectural modeling from unordered photo collections. TOG'08
	- A.-L. Chauve, P. Labatut, and J.-P. Pons. Robust piecewise planar 3d reconstruction and completion from large-scale unstructured point data. CVPR'10
	- Sanja Fidler, Sven Dickinson, and Raquel Urtasun. 3d object detection and viewpoint estimation with a deformable 3d cuboid model. NIPS'12
	- F. Lafarge and P. Alliez. Surface reconstruction through point set structuring. CGF'13
	- A. Bodis-Szomoru, H. Riemenschneider, and L. Van Gool. Fast, approximate piecewise-planar modeling based on sparse structure-from-motion and superpixels. CVPR'14
	- Noa Fish, Melinos Averkiou, Oliver van Kaick, Olga Sorkine-Hornung, Daniel Cohen-Or, and Niloy J. Mitra. Meta-representation of shape families. TOG'14
	- Adrien Kaiser, José Alonso Ybáñez Zepeda, and Tamy Boubekeur. A survey of simple geometric primitives detection methods for captured 3d data. CGF'19
- Parts/Primitives:
	- Legacy:
		- L. G. Roberts. Machine perception of three-dimensional solids. PhD thesis, Massachusetts Institute of Technology, 1963
		- Donald D Hoffman and Whitman A Richards. Parts of recognition. Cognition, 18(1-3):65–96, 1984
		- Alex Pentland. Parts: Structured descriptions of shape. AAAI'86
		- **geon**: I. Biederman. Recognition-by-components: a theory of human image understanding. Psychological review, 94(2):115, 1987
		- R. Schnabel, P. Degener, and R. Klein. Completion and reconstruction with primitive shapes. CGF/Eurographics'09
			- Problem: completion and reconstruction;
			- primitives as guidance, energy-based optimization;
	- Ransac and fitting:
		- R. Schnabel, R. Wahl, and R. Klein. Efficient ransac for point-cloud shape detection. CGF'07
		- **Fitting**: Narunas Vaskevicius and Andreas Birk. Revisiting superquadric fitting: A numerically stable formulation. PAMI'17
		- **Globfit**: Yangyan Li, Xiaokun Wu, Yiorgos Chrysanthou, Andrei Sharf, Daniel Cohen-Or, and Niloy J. Mitra. Globfit: consistently fitting primitives by discovering global relations. TOG'11
		- Adrien Kaiser, José Alonso Ybáñez Zepeda, and Tamy Boubekeur. A survey of simple geometric primitives detection methods for captured 3d data. CGF'19
			- Primitives:
				- Size, orientation, position, convex, symmetric, assembles;
				- Primitives: planes, cuboids/boxes, spheres/cylinders/cones, ellipsoids/tori/...
			- Approaches: Ransac, Hough Transform, Clustering; (region growing, ...), Assembling Primitives;
	- Cosegmentation:
		- A. Golovinskiy and T. Funkhouser. Learning Consistent Segmentation of 3D Models. CG'09
			- Problem: segment a set of models;
			- Energy based: a graph, similar parts across shapes should have consistent assignment;
		- Qi-Xing Huang, Vladlen Koltun, and Leonidas J. Guibas. Joint shape segmentation with linear programming. TOG'11
		- Mehmet Ersin Yümer and Levent Burak Kara. Co-abstraction of shape collections. TOG'12
		- Vladimir G. Kim, Wilmot Li, Niloy J. Mitra, Siddhartha Chaudhuri, Stephen DiVerdi, and Thomas A. Funkhouser. Learning part-based templates from large collections of 3d shapes. TOG'13
			- Jointly learn parts from multiple shapes
		- **BAE-Net**: Zhiqin Chen, Kangxue Yin, Matthew Fisher, Siddhartha Chaudhuri, and Hao Zhang. BAE-Net: Branched autoencoder for shape co-segmentation. CVPR'19
			- https://github.com/czq142857/BAE-NET
			- Task: unsupervised co-segmentation;
	- Unsupervised part discovery:
		- Shubham Tulsiani, Hao Su, Leonidas J. Guibas, Alexei A. Efros, Jitendra Malik. Learning Shape Abstractions by Assembling Volumetric Primitives. CVPR'17
			- Supervision: unsupervised, reconstruction loss;
		- **Superquadrics**: Despoina Paschalidou, Ali Osman Ulusoy, and Andreas Geiger. Superquadrics revisited: Learning 3d shape parsing beyond cuboids. CVPR'19
			- https://github.com/paschalidoud/superquadric_parsing
	- Supervised:
		- **3d-prnn**: Chuhang Zou,Ersin Yumer, Jimei Yang, Duygu Ceylan,and Derek Hoiem. 3d-prnn: Generating shape primitives with recurrent neural networks. ICCV'17
		- **SFPN**: Lingxiao Li, Minhyuk Sung, Anastasia Dubrovina, Li Yi, and Leonidas J. Guibas. Supervised fitting of geometric primitives to 3d point clouds. CVPR'19
		- Anastasia Dubrovina, Fei Xia, Panos Achlioptas, Mira Shalah, Raphael Groscot, Leonidas Guibas. Composite Shape Modeling via Latent Space Factorization. ICCV'19
			- Input: 3D;
			- Output: editable object by manipulating semantic space;
			- Backbone:
				- Input 3D voxel -> 3D-CNN -> partition unity to 1;
				- Each part feature -> decoder -> STN -> obj;
		- **CompoNet**: Nadav Schor, Oren Katzir, Hao Zhang, and Daniel Cohen-Or. CompoNet: Learning to generate the unseen by part synthesis and composition. ICCV'19
			- https://github.com/nschor/CompoNet
			- Model:
				- Part synthesis unit: VAE for each part separately;
				- Part composition unit: compose the part;
		- **Sagnet**: Zhijie Wu, Xiang Wang, Di Lin, Dani Lischinski, Daniel Cohen-Or, and Hui Huang. Sagnet: Structure-aware generative network for 3d-shape modeling. SIGGRAPH'19
			- https://github.com/zhijieW94/SAGNet
			- Model:
				- k voxel maps;
				- K pairwise relationship;
				- GRU (RNN)
			- Training:
				- First phase: 2-way VAE for reconstruction loss;
	- Hierarchical/Recursive/Graph/Scene-graph:
		- James D Foley, Foley Dan Van, Andries Van Dam, Steven K Feiner, John F Hughes, J Hughes, and Edward Angel. Computer graphics: principles and practice. 1996
		- Yanzhen Wang, Kai Xu, Jun Li, Hao Zhang, Ariel Shamir, Ligang Liu, Zhi-Quan Cheng, and Yueshan Xiong. Symmetry Hierarchy of Man-Made Objects. CGF'11
		- Symmetry hierarchy: 3D geometry is hierarchically grouped by either attachment or symmetric relationships;
		- **GRASS**. Jun Li, Kai Xu, Siddhartha Chaudhuri, Ersin Yumer, Hao Zhang, Leonidas Guibas. GRASS: Generative Recursive Autoencoders for Shape Structures. SIGGRAPH 2017
			- Regularity/symmetry;
			- https://github.com/kevin-kaixu/grass_pytorch
		- **Im2Struct**: Chengjie Niu, Jun Li, Kai Xu. Im2Struct: Recovering 3D Shape Structure from a Single RGB Image. CVPR'18
			- https://github.com/chengjieniu/Im2Struct
			- Recursive NN to iteratively predict primitives;
		- **SCORES**: Chenyang Zhu, Kai Xu, Siddhartha Chaudhuri, Renjiao Yi, Hao Zhang. SCORES: Shape Composition with Recursive Substructure Priors. SIGGRAPH Asia'18
		- **StructureNet**: Kaichun Mo, Paul Guerrero, Li Yi, Hao Su, Peter Wonka, Niloy Mitra, Leonidas J. Guibas. StructureNet: Hierarchical Graph Networks for 3D Shape Generation. 2019
		- **GRAINS**: Manyi Li, Akshay Gadi Patil, Kai Xu, Siddhartha Chaudhuri, Owais Khan, Ariel Shamir, ChangheTu, Baoquan Chen, Daniel Cohen-Or, and Hao Zhang. GRAINS: Generative recursive autoencoders for indoor scenes. TOG'19
		- **StructEdit**: Kaichun Mo, Paul Guerrero, Li Yi, Hao Su, Peter Wonka, Niloy J. Mitra, Leonidas Guibas. StructEdit: Learning Structural Shape Variations. 2019
		- **GNN**: Kai Wang, Yu-an Lin, Ben Weissmann, Manolis Savva, Angel X. Chang, and Daniel Ritchie. PlanIT: Planning and Instantiating Indoor Scenes with Relation Graph and Spatial Prior Networks. SIGGRAPH'19
		- Despoina Paschalidou, Luc Gool, and Andreas Geiger. Learning unsupervised hierarchical part decomposition of 3d objects from a single rgb image. CVPR'20
			- https://github.com/paschalidoud/hierarchical_primitives
			- 3 Networks:
				- Partition network: binary partition, each part with feature;
				- Structure network: inside/outside assignment;
				- Geometry network: superquadratics fitting;
	- Siddhartha Chaudhuri and Vladlen Koltun. Data-driven suggestions for creativity support in 3d modeling. ACM SIGGRAPH Asia'10
	- Charlie Nash and Chris KI Williams. The shape variational autoencoder: A deep generative model of part-segmented 3d objects. CGF'17
	- Hao Wang, Nadav Schor, Ruizhen Hu, Haibin Huang, Daniel Cohen-Or, and Hui Huang. Global-to-local generative model for 3d shapes. SIGGRAPH Asia'18
	- Jialei Huang, Guanqi Zhan, Qingnan Fan, Kaichun Mo, Lin Shao, Baoquan Chen, Leonidas J. Guibas, Hao Dong. Generative 3D Part Assembly via Dynamic Graph Learning. NeurIPS'20
		- https://hyperplane-lab.github.io/Generative-3D-Part-Assembly/
		- https://github.com/hyperplane-lab/Generative-3D-Part-Assembly
		- Task: given part point cloud, predict assembly;
		- GNN for relation reasoning, pooling for equivalent parts (4 legs)...
	- Rundi Wu, Yixin Zhuang, Kai Xu, Hao Zhang, and Baoquan Chen. PQ-NET: A generative part seq2seq network for 3D shapes. CVPR'20
		- https://github.com/ChrisWu1997/PQ-NET
		- Sequentially, one part at a time by GRU;
		- Assumes part given together with shape;
	- **AtlasNetV2**: Theo Deprelle, Thibault Groueix, Matthew Fisher, Vladimir Kim, Bryan Russell, and Mathieu Aubry. Learning elementary structures for 3d shape generation and matching. NeurIPS'19
		- https://github.com/TheoDEPRELLE/AtlasNetV2
		- Assume all 3D data similar to a common template;
		- Learn to MLP-mapping or translate;
		- correspondence error if gt available, otherwise CD;
	- Despoina Paschalidou, Angelos Katharopoulos, Andreas Geiger, Sanja Fidler. Neural Parts: Learning Expressive 3D Shape Abstractions With Invertible Neural Networks. CVPR'21
		- https://paschalidoud.github.io/neural_parts
		- https://github.com/paschalidoud/neural_parts
- **CAD** (retrieval, Morphable):
	- **Morphable model**:
		- Legacy:
			- 3DMM: Volker Blanz and Thomas Vetter. A morphable model for the synthesis of 3D faces. In 26th Annual Conference on Computer Graphics and Interactive Techniques'99
				- Human face;
		- Deform **each vertice**:
			- DeformNet: A Kuryenkov, J Ji, A Garg, V Mehta, J Gwak, C Choy, S Savarese. DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction from a Single Image. 2017
				- Insight: first CNN retrive a **prototype**, then CNN to deform
				- https://deformnet-site.github.io/DeformNet-website/
				- Input: single image; output: offset/deformation;
			- ALIGNet: Rana Hanocka, Noa Fish, Zhenhua Wang, Raja Giryes, Shachar Fleishman, and Daniel Cohen-Or. ALIGNet: Partial-Shape agnostic alignment via unsupervised learning. TOG'18
				- https://github.com/ranahanocka/ALIGNet
				- Input: source, **partial** target;
				- Learn a masked-autoencoder;
			- Dominic Jack, Jhony K. Pontes, Sridha Sridharan, Clinton Fookes, Sareh Shirazi, Frederic Maire, Anders Eriksson. Learning Free-Form Deformations for 3D Object Reconstruction. ACCV'18
				- https://github.com/jackd/template_ffd
				- Input: image, some templates;
				- Learn to infer offset for each template;
			- Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan C. Russell, and Mathieu Aubry. Deep self-supervised cycle-consistent deformation for few-shot shape segmentation. Eurographics'19
				- Input: source A, target B;
				- Output: deformation;
				- Model:
					- Backbone: A, B go through pointnet, feature vA, vB;
					- Tranformation vectors: concatenate \[vA, vB\] then MLP to get p1, ..., pK;
					- Deformation: point on A go through p1, ..., pK to get final shape;
				- Supervision:
					- Chamfer distance;
					- 2-consistency: p-fAB fBA(p)
					- 3-consistency: triplet shape A, B, C, then AB, BA, CA;
			- **3DN**: Weiyue Wang, Duygu Ceylan, Radomir Mech, and Ulrich Neumann. 3dn: 3d deformation network. CVPR'19
				- https://github.com/laughtervv/3DN
				- Input: source mesh, target model (2D image/3D model);
				- Backbone:
					- Source encoder: PointNet;
					- Target encoder: CNN/PointNet for image/pc;
					- Offset Decoder: source(xyz) + source/target encoded feature -> MLP -> offset;
				- Supervision:
					- CD, EMD between deformed mesh and target;
					- Symmetry loss;
			- **DeformSyncNet**: Minhyuk Sung, Zhenyu Jiang, Panos Achlioptas, Niloy J. Mitra, and Leonidas J. Guibas. DeformSyncNet: Deformation transfer via synchronized shape deformation spaces. SIGGRAPH Asia'20
				- https://github.com/Steve-Tod/DeformSyncNet
				- Problem definition: 
					- shape editting;
					- Editting transferrable the deformation of shape pairs (a1, b1) to other pairs (a2, b2), (a3, b3)...
				- Model:
					- X x V -> Y; X: nx3 shape; v: vector representing deformation;
					- Project shape-editting to deformation space, s.t. ||Bx z - Ax v||;
					- Given source x, target y, learn dictionary model F(.) and encoder E(.) such that:
						- y = x + F(x)(E(y)-E(x))
			- **Neural cages**: Wang Yifan, Noam Aigerman, Vladimir Kim, Siddhartha Chaudhuri, and Olga Sorkine-Hornung. Neural cages for detail-preserving 3d deformations. CVPR'20
				- https://github.com/yifita/deep_cage
		- Deform handles:
			- **biharmonic coordinates**: Yu Wang, Alec Jacobson, Jernej Barbic, and Ladislav Kavan. Linear subspace design for real-time shape deformation.  SIGGRAPH'15
			- **DeepMetaHandles**: Minghua Liu, Minhyuk Sung, Radomir Mech, Hao Su. DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with Biharmonic Coordinates. CVPR'21
				- https://github.com/Colin97/DeepMetaHandles
		- Qingyang Tan, Lin Gao, Yu-Kun Lai, Jie Yang,and Shihong Xia. Mesh-based autoencoders for localized deformation component analysis. AAAI'18
			- https://github.com/aldehydecho/convMesh
		- Qingyang Tan, Lin Gao, Yu-Kun Lai, and Shihong Xia. Meshvae: Variational autoencoders for deforming 3d mesh models. CVPR'18
		- Jie Yang, Kaichun Mo, Yu-Kun Lai, Leonidas J. Guibas, and Lin Gao. DSM-Net: Disentangled structured mesh net for controllable generation of fine geometry, 2020.
		- Articulated objects (Human):
			- Allen, B., Curless, B., Popovic, Z.: Articulated body deformation from range scan data. SIGGRAPH'02
			- Brett Allen, Brian Curless, Zoran Popovic. The space of human body shapes: reconstruction and parameterization from range scans. TOG'03
			- Dragomir Anguelov, Praveen Srinivasan,Daphne Koller, Sebastian Thrun, Jim Rodgers, and James Davis. SCAPE: shape completion and animation of people. TOG'05
			- Allen, B., Curless, B., Popovic, Z.: Learning a correlated model of identity and pose-dependent body shape variation for real-time synthesis. Symposium on Computer Animation'06
			- Silvia Zuffi and Michael J. Black. The stitched puppet: A graphical model of 3d human shape and pose. CVPR'15
			- Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael J. Black. SMPL: a skinned multi-person linear model. TOG'15
			- A. Kanazawa, M. J. Black, D. W. Jacobs, and J. Malik. End-to-end recovery of human shape and pose. CVPR'18
			- **3d-coded**: Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan C. Russell, and Mathieu Aubry. 3d-coded: 3d correspondences by deep deformation. ECCV'18
				- http://imagine.enpc.fr/~groueixt/3D-CODED/
				- https://github.com/ThibaultGROUEIX/3D-CODED
			- **Chart**: Heli Ben-Hamu, Haggai Maron, Itay Kezurer, Gal Avineri, and Yaron Lipman. Multi-chart generative surface modeling. TOG'18
				- https://github.com/helibenhamu/multichart3dgans
				- Chart = Atlas?
				- Assumption: a sparse set of landmark correspondences available (6 for bones and 21 for human)
				- Basic building modules: Conformal toric charts;
					-  H. Maron, M. Galun, N. Aigerman, M. Trope, N. Dym, E. Yumer, V. G. KIM, and Y. Lipman. Convolutional neural networks on surfaces via seamless toric covers. SIGGRAPH, 2017
				- Dataset: human body and anatomical bone surfaces (teeth)
			- **Tex2shape**: Thiemo Alldieck, Gerard Pons-Moll, Christian Theobalt, and Marcus Magnor. Tex2shape: Detailed full human body geometry from a single image. ICCV'19
				- https://github.com/thmoa/tex2shape
				- SMPL + barycentric coord;
			- Keyang Zhou, Bharat Lal Bhatnagar, and Gerard Pons-Moll. Unsupervised shape and pose disentanglement for 3d meshes. ECCV'20
				- https://github.com/kzhou23/shape_pose_disent
				- SMPL-based;
				- Separate pose and shape branch;
				- Self-consistency + cross-consistency constraint;
	- Jason Rock, Tanmay Gupta, Justin Thorsen, JunYoung Gwak, Daeyun Shin, and Derek Hoiem. Completing 3d object shape from one depth image. CVPR'15
		- Non-DL, retrieve a similar mesh;
		- task: input depth map, output completed obj;
	- A Kar, S Tulsiani, J Carreira, J Malik. Category-Specific Object Reconstruction from a Single Image. CVPR'15
		- https://github.com/akar43/CategoryShapes
		- Task: input some images, output camera poses and 3d model;
		- NRSfM [10] to jointly estimate the two;
	- C. Kong, C.-H. Lin, and S. Lucey. Using locally corresponding CAD models for dense 3D reconstructions from a single image. CVPR'17
	- A. Kanazawa, S. Tulsiani, A. A. Efros, and J. Malik. Learning category-specific mesh reconstruction from image collections. ECCV'18
		- Morphable mesh;
	- **SDM-NET**: Lin Gao, Jie Yang, Tong Wu, Yu-Jie Yuan, Hongbo Fu, Yu-Kun Lai, and Hao(Richard) Zhang. SDM-NET: Deep generative network for structured deformable mesh. TOG'19
	- Eloi Mehr, Ariane Jourdan, Nicolas Thome, Matthieu Cord, and Vincent Guitteny. DiscoNet: Shapes learning on disconnected manifolds for 3d editing. ICCV'19
	- Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan C. Russell, and Mathieu Aubry. Deep self-supervised cycle-consistent deformation for few-shot shape segmentation. Eurographics'19
	- Feng Liu and Xiaoming Liu. Learning implicit functions for topology-varying dense 3d shape correspondence. NeurIPS'20
		- https://github.com/liuf1990/Implicit_Dense_Correspondence
	- **Shapeflow**: Chiyu Jiang, Jingwei Huang, Andrea Tagliasacchi, and Leonidas Guibas. Shapeflow: Learnable deformations among 3D shapes. NeurIPS'20
		- https://github.com/maxjiang93/ShapeFlow
		- CNF-based;
	- **DIT-Net**: Yu Deng, Jiaolong Yang, Xin Tong. Deformed Implicit Field: Modeling 3D Shapes with Learned Dense Correspondence. CVPR'21
		- https://github.com/microsoft/DIF-Net
	- Shuo Yang, Min Xu, Haozhe Xie, Stuart Perry, Jiahao Xia. Single-View 3D Object Reconstruction From Shape Priors in Memory. CVPR'21
- **CSG**:
	- CSG-Trees: James D Foley, Foley Dan Van, Andries Van Dam, Steven K Feiner, John F Hughes, J Hughes, and Edward Angel. Computer graphics: principles and practice. 1996
	- **CSGNet**: Gopal Sharma, Rishabh Goyal, Difan Liu, Evangelos Kalogerakis, Subhransu Maji. CSGNet: Neural Shape Parser for Constructive Solid Geometry. CVPR'18
- **Chart**: Heli Ben-Hamu, Haggai Maron, Itay Kezurer, Gal Avineri, and Yaron Lipman. Multi-chart generative surface modeling. TOG'18
- **SIF**: Kyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna, William T Freeman, and Thomas Funkhouser. Learning shape templates with structured implicit functions. ICCV'19
	- https://github.com/google/ldif
- Latest:
	- Zerong Zheng, Tao Yu, Qionghai Dai, Yebin Liu. Deep Implicit Templates for 3D Shape Representation. CVPR'21
		- https://github.com/ZhengZerong/DeepImplicitTemplates

## 5. Implicit Functions (N-SDF)
- Legacy:
	- B. Curless and M. Levoy. A volumetric method for building complex models from range images. SIGGRAPH'96
	- **RBF**: Jonathan C. Carr, Richard K. Beatson, Jon B. Cherrie, Tim J. Mitchell, W. Richard Fright, Bruce C. McCallum, and Tim R. Evans. Reconstruction and representation of 3d objects with radial basis functions. SIGGRAPH'01
	- Greg Turk and James F. O’Brien. Modelling with implicit surfaces that interpolate. TOG'02
	- **Unity implicits**: Yutaka Ohtake, Alexander Belyaev, Marc Alexa, Greg Turk, and Hans-Peter Seidel. Multi-level partition of unity implicits, volume 22. ACM, 2003
	- Chen Shen, James F. O'Brien, and Jonathan Richard Shewchuk. Interpolating and approximating implicit surfaces from polygon soup. TOG'04
- Render for implicit models:
	- Marching Cube;
	- John C. Hart. Sphere tracing: A geometric method for the antialiased ray tracing of implicit surfaces. 1996
	- **Surface-Finding**: Sarah F. Frisken, Ronald N. Perry, Alyn P. Rockwood, and Thouis R. Jones. Adaptively sampled distance fields: A general representation of shape for computer graphics. 2000
- Generalized Neural-SDF:
	- **OccNet**: Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas Geiger. Occupancy networks: Learning 3d reconstruction in function space. CVPR'19
		- Insight: new 3D representation, could generate mesh at any resolution;
		- https://github.com/autonomousvision/occupancy_networks
		- Input image; output: **continuous decision boundary of a deep-NN**;
		- Learn an occupancy function: R3 to [0,1];
		- Surface at inference time: Multiresolution IsoSurface Extraction (MISE) or Marching Cube;
	- **DeepSDF**: Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven Lovegrove. DeepSDF: Learning continuous signed distance functions for shape representation. CVPR'19
		- Insight: point-based SDF;
		- https://github.com/facebookresearch/DeepSDF
		- Formulation: given a point x, a NN with latent code z as a classifier \
			<img src="/CV-3D/images/3d_output/deepsdf-1.png" alt="drawing" width="350"/>
		- Autoencoder: \
			<img src="/CV-3D/images/3d_output/deepsdf-2.png" alt="drawing" width="400"/>
		- Auto-decoder (encoder-less) training and inference: \
			<img src="/CV-3D/images/3d_output/deepsdf-3.png" alt="drawing" width="400"/>
			<img src="/CV-3D/images/3d_output/deepsdf-4.png" alt="drawing" width="400"/>
	- **SAL**: Matan Atzmon and Yaron Lipman. SAL: Sign agnostic learning of shapes from raw data. CVPR'20
	- SAL++: Matan Atzmon and Yaron Lipman. SAL++: Sign agnostic learning with derivatives. arxiv'20
	- **BSPNet**: Zhiqin Chen, Andrea Tagliasacchi, and Hao Zhang. BSPNet: Generating compact meshes via binary space partitioning. CVPR'20
	- **Dualsdf**: Zekun Hao, Hadar Averbuch-Elor, Noah Snavely, and Serge Belongie. Dualsdf: Semantic shape manipulation using a two-level representation. arXiv, 2020.
	- Yueqi Duan, Haidong Zhu, He Wang, Li Yi, Ram Nevatia, and Leonidas J. Guibas. Curriculum deepsdf, 2020
		- https://github.com/haidongz-usc/Curriculum-DeepSDF
		- Built on DeepSDF, train with progressive difficulty (error tolenrance)
	- Chiyu Max Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias Nießner, and Thomas A. Funkhouser. Local implicit grid representations for 3d scenes. 2020
	- Rohan Chabra, Jan Eric Lenssen, Eddy Ilg, Tanner Schmidt, Julian Straub, Steven Lovegrove, and Richard Newcombe. Deep local shapes: Learning local SDF priors for detailed 3d reconstruction. CoRR'20
- Differentiable rendering:
	- **SRN**: Vincent Sitzmann, Michael Zollhofer, and Gordon Wetzstein. Scene representation networks: Continuous 3d-structure-aware neural scene representations. NeurIPS'19
		- https://github.com/vsitzmann/scene-representation-networks
	- **NERF**: Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. NeRF: Representing scenes as neural radiance fields for view synthesis. ECCV'20
- Sampling technique:
	- Wang Yifan, Shihao Wu, Cengiz Öztireli, Olga Sorkine-Hornung. Iso-Points: Optimizing Neural Implicit Surfaces With Hybrid Representations. CVPR'21
- **DISN**: Qiangeng Xu, Weiyue Wang, Duygu Ceylan, Radomir Mech, and Ulrich Neumann. Disn: Deep implicit surface network for high-quality single-view 3d reconstruction. 2019
- **IM-Net**: Zhiqin Chen and Hao Zhang. Learning implicit fields for generative shape modeling. CVPR'19
	- https://github.com/czq142857/implicit-decoder
- **DSIF**: Kyle Genova, Forrester Cole, Avneesh Sud, Aaron Sarna, and Thomas A. Funkhouser. Deep structured implicit functions. CoRR, abs/1912.06126, 2019
- **Pifu**: Shunsuke Saito, Zeng Huang, Ryota Natsume, Shigeo Morishima, Angjoo Kanazawa, and Hao Li. Pifu: Pixel-aligned implicit function for high-resolution clothed human digitization. ICCV'19
- **PIFuHD**: Shunsuke Saito, Tomas Simon, Jason Saragih, and Hanbyul Joo. PIFuHD: Multi-level pixel-aligned implicit function for high-resolution 3D human digitization. CVPR'20
- Michael Niemeyer, Lars M. Mescheder, Michael Oechsle, and Andreas Geiger. Occupancy flow: 4d reconstruction by learning particle dynamics. ICCV'19
- Boyang Deng, Kyle Genova, Soroosh Yazdani, Sofien Bouaziz, Geoffrey Hinton, Andrea Tagliasacchi. CvxNet: Learnable Convex Decomposition. CVPR'20
	- https://cvxnet.github.io/
	- https://github.com/tensorflow/graphics/tree/master/tensorflow_graphics/projects/cvxnet
- Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, and Yaron Lipman. Implicit geometric regularization for learning shapes. CoRR'20
- Thomas Davies, Derek Nowrouzezahrai, and Alec Jacobson. On the effectiveness of weight-encoded neural implicit 3D shapes. arxiv'20
- Michael Niemeyer, Lars Mescheder, Michael Oechsle, and Andreas Geiger. Differentiable volumetric rendering: Learning implicit 3D representations without 3D supervision. CVPR'20
- Saurabh Singh, Danhang Danny Tang, Phil Chou, Christian Haene, Mingsong Dou, Sean Fanello, Jonathan Taylor, Onur Gonen Guleryuz, Yinda Zhang, Shahram Izadi, Andrea Tagliasacchi, Sofien Bouaziz, and Cem Keskin. Deep implicit volume compression. CVPR'20
- Edgar Tretschk, Ayush Tewari, Vladislav Golyanik, Michael Zollhöfer, Carsten Stoll, and Christian Theobalt. PatchNets: Patch-Based Generalizable Deep Implicit 3D Shape Representations. ECCV'20
- Matthew Tancik, Pratul P. Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan T. Barron, and Ren Ng. Fourier features let networks learn high frequency functions in low dimensional domains. NeurIPS'20
- Vincent Sitzmann, Julien NP Martel, Alexander W Bergman, David B Lindell, and Gordon Wetzstein. Implicit neural representations with periodic activation functions. NeurIPS'20
- Latest:
	- Moritz Ibing, Isaak Lim, Leif Kobbelt. 3D Shape Generation With Grid-Based Implicit Functions. CVPR'21

## 2.5D, Depth, Skeleton, 3D-Aware 2D Cues...
- Depth:
	- Wei Yin, Yifan Liu, Chunhua Shen, and Youliang Yan. Enforcing geometric constraints of virtual normal for depth prediction. ICCV'19
- S. Galliani and K. Schindler. Just look at the image: Viewpoint-specific surface normal prediction for improved multi-view reconstruction. CVPR'16
	- Estimate **normal** of depth map; then improve depth map fusion;
- **3D-INN**: J Wu, T Xue, J Lim, Y Tian, J Tenenbaum, A Torralba, and W Freeman. Single Image 3D Interpreter Network, ECCV'16, IJCV'18
	- Key insight: skeleton representation for 3D objects (so keypoints infers 3D);
	- Input: single image; output:	2d keypoints as well as 3d structure;
	- Keypoint detection (CNN) -> keypoint refinement (mini-network like auto-encoder) -> 3D interpreter -> Projection Layer;\
	<img src="/CV-3D/images/3d_output/3d-inn.png" alt="drawing" width="600"/>
- **MarrNet**: J Wu, Y Wang, T Xue, X Sun, W Freeman, and J Tenenbaum. MarrNet: 3D Shape Reconstruction via 2.5D Sketches. NIPS'17
	- Key insight: 3D-cues first (2.5-D: normal, depth, silhouette), then 3D shape
	- http://marrnet.csail.mit.edu/
	- https://github.com/jiajunwu/marrnet
	- Input: image; output: voxel;
	- Network: encoder (ResNet-18) - decoder (input normal image + depth image masked by silhouette);
	- Supervision: (2D-3D Reprojection consistency)
		- Depth map with voxel: L2;
		- Surface normal; (surface orthogonal to normal should be 1)
	<img src="/CV-3D/images/3d_output/marrnet.png" alt="drawing" width="600"/>
- Wilfried Hartmann, Silvano Galliani, Michal Havlena, Luc Van Gool, and Konrad Schindler. Learned multi-patch similarity. ICCV'17
- **DeepMVS**: P Huang, K Matzen, J Kopf, N Ahuja, and J Huang. DeepMVS: Learning Multi-view Stereopsis. CVPR'18
- **ShapeHD**: J. Wu, C. Zhang, X. Zhang, Z. Zhang, W. T. Freeman, and J. B. Tenenbaum. Learning shape priors for single-view 3D completion and reconstruction. ECCV'18
	- Key insigth: improve on MarrNet with naturalness (pretrained discriminator) to solve ambiguity, with Wasserstein-GAN loss;
	- https://github.com/xiumingzhang/GenRe-ShapeHD
	- Input: single view; Output: 3D voxel completion/reconstruction; \
	<img src="/CV-3D/images/3d_output/shapehd.png" alt="drawing" width="600"/>
- Simon Donne and Andreas Geiger. Learningnon-volumetric depth fusion using successive reprojections. CVPR'19