# Adversarial Learning

- Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, Aleksander Madry. Adversarial Examples Are Not Bugs, They Are Features. NeurIPS'19
	- Some features are robust, some are non-robust
	- Imagine binary classifcation: f(x) and y (+/-1)
	- Insight: create a new dataset, manipulate x (originally cat), s.t., turns it into a dog with cat-looking with dog-robust-feature and labled it as a dog in the new dataset;
- A Game Theoretic Approach to Class-wise Selective Rationalization. NIPS'19
